{"cells":[{"cell_type":"markdown","id":"06b80969-3ce7-45e5-bbdc-7c6a8b1ff9f5","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","# **Retail Sales Dataset 2018-2022**\n","\n","## **Lab 2. Data Wrangling**\n","\n","Estimated time needed: **30** minutes\n","\n","### **Dataset Attributes**\n","*   Date: year and month\n","*   SKU: unique code consisting of letters and numbers that identify each product\n","*   Group: group of related products which share some common attributes\n","*   Units Pkg: package weight (kg)\n","*   Avg Price Pkg: average price per package\n","*   Sales Pkg: total package sales per month\n","\n","### **Target Field**\n","*   Turnover per month\n","\n","## **Objectives**\n","\n","After completing this lab you will be able to:\n","\n","*   Detect and handle missing values\n","*   Correct data format\n","*   Standardize and normalize data\n"]},{"cell_type":"markdown","id":"197648eb-9d44-43b0-ae07-43ba1b4795f5","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#identify_handle_missing_values\"\u003eIdentify and handle missing values\u003c/a\u003e\n","        \u003cul\u003e\n","            \u003cli\u003e\u003ca href=\"#count-missing-values\"\u003eCount missing values\u003c/a\u003e\u003c/li\u003e\n","            \u003cli\u003e\u003ca href=\"#correct_data_format\"\u003eCorrect data format\u003c/a\u003e\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#add_group_sort\"\u003eAdding new column, grouping and sorting data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#data_standardization\"\u003eData standardization\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#data_normalization\"\u003eData normalization (centering/scaling)\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#binning\"\u003eBinning\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#indicator\"\u003eIndicator variable\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"9d7a9a56-22c0-414d-8a33-d569db33612d","metadata":{},"outputs":[],"source":["## **What is the purpose of data wrangling?**\n","Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"]},{"cell_type":"markdown","id":"09918bf8-5ab2-43b6-a72a-090e57f689b2","metadata":{},"outputs":[],"source":["\u003ch3\u003eImport Data\u003c/h3\u003e\n","\u003cp\u003e\n","You can find the \"Retail Sales Dataset 2018-2022\" from the following link: \u003ca href=\"https://www.kaggle.com/datasets/tsmldata/retail-sales-dataset-2018-2022?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\"\u003ehttps://www.kaggle.com/datasets/tsmldata/retail-sales-dataset-2018-2022\u003c/a\u003e. \n","We will be using this dataset throughout this course.\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"5ac9735c-cefd-4c54-adb6-8c6989c455d0","metadata":{},"outputs":[],"source":["\u003ch3\u003eImport pandas\u003c/h3\u003e\n","If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"]},{"cell_type":"code","id":"b98507ca-9a35-4faf-8bc1-470426039f57","metadata":{},"outputs":[],"source":["#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n#install specific version of libraries used in lab\n#! mamba install pandas==1.3.3\n#! mamba install numpy=1.21.2\n"]},{"cell_type":"code","id":"739d1567-40a5-4840-9c68-02d458375d3b","metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\n\npd.set_option('display.precision', 2)"]},{"cell_type":"markdown","id":"cfc19ae7-dec7-4e9c-9ce5-0cb967fd030f","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb\u003eReading the dataset from the URL\u003c/b\u003e\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"40a0ad73-0f83-4d18-97ae-20d1b4c02b45","metadata":{},"outputs":[],"source":["First, we assign the URL of the dataset to \"filename\".\n"]},{"cell_type":"markdown","id":"94479e4f-2a79-4a05-8a00-e447bf435e99","metadata":{},"outputs":[],"source":["This dataset was hosted on IBM Cloud object. Click \u003ca href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\"\u003eHERE\u003c/a\u003e for free storage.\n"]},{"cell_type":"code","id":"d94025b3-ffc6-42a6-ad9e-b0accb6a999e","metadata":{},"outputs":[],"source":["filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0OWKEN/sales_1.csv\""]},{"cell_type":"markdown","id":"6f03c8a8-cd3d-4d57-abce-bd965554de73","metadata":{},"outputs":[],"source":["Use the Pandas method \u003cb\u003eread_csv()\u003c/b\u003e to load the data from the web address. Set the parameter  \"names\" equal to the Python list \"headers\".\n"]},{"cell_type":"code","id":"44e17979-1b7d-4b4e-8e56-54bd4d33da57","metadata":{},"outputs":[],"source":["df = pd.read_csv(filename)"]},{"cell_type":"markdown","id":"f60b662c-bc12-4548-9693-a5d577dccca8","metadata":{},"outputs":[],"source":["Use the method \u003cb\u003ehead()\u003c/b\u003e to display the first five rows of the dataframe.\n"]},{"cell_type":"code","id":"73775354-ccc2-45b8-bb51-77fce2533850","metadata":{},"outputs":[],"source":["# To see what the data set looks like, we'll use the head() method.\ndf.head(5)"]},{"cell_type":"markdown","id":"cbf77c8c-0d18-46d9-8935-e218f24f3873","metadata":{},"outputs":[],"source":["Let's check if there are any uncorrect values.\n"]},{"cell_type":"code","id":"e8c9a9d6-8221-4649-818a-b67118dd18f4","metadata":{},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","id":"3f9dacd4-a216-4bdd-9bff-77ca430cbe02","metadata":{},"outputs":[],"source":["As we can see above, there are no uncorrect values.\n"]},{"cell_type":"markdown","id":"cf0e8152-e254-4211-acae-cfa4f51986b9","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"identify_handle_missing_values\"\u003eIdentify missing values\u003c/b\u003e\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"732a9fcf-f6ba-4052-bfbc-97dc4c73730c","metadata":{},"outputs":[],"source":["\u003ch3\u003e\u003cb\u003eEvaluating for Missing Data\u003c/b\u003e\u003c/h3\u003e\n","\n","The missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n","\n","\u003col\u003e\n","    \u003cli\u003e\u003cb\u003e.isnull()\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb\u003e.notnull()\u003c/b\u003e\u003c/li\u003e\n","\u003c/ol\u003e\n","The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"]},{"cell_type":"code","id":"f26023a2-e20a-4446-9321-bd2d5f5c2954","metadata":{},"outputs":[],"source":["missing_data = df.isnull()\nmissing_data.head(5)"]},{"cell_type":"markdown","id":"3d68bf14-c6d4-49ca-9b9d-10c67043ac26","metadata":{},"outputs":[],"source":["\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"]},{"cell_type":"markdown","id":"4d771af7-71e8-4cf0-81af-48d15ba96bbf","metadata":{},"outputs":[],"source":["\u003ch3\u003e\u003cb id=\"count-missing-values\"\u003eCount missing values in each column\u003c/b\u003e\u003c/h3\u003e\n","\u003cp\u003e\n","Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method \u003ccode\u003evalue_counts()\u003c/code\u003e counts the number of \"True\" values. \n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"f2a2292c-1d5d-4074-9900-8c3aae2f4aac","metadata":{},"outputs":[],"source":["for column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    "]},{"cell_type":"markdown","id":"58d75028-e1b9-4160-9cbd-69e27b3dfded","metadata":{},"outputs":[],"source":["Based on the summary above, each column has 4138 rows of data and there are no columns that contain missing data.\n"]},{"cell_type":"markdown","id":"b5f26b0f-3452-4c2b-8723-abeceb963ca3","metadata":{},"outputs":[],"source":["\u003ch3\u003e\u003cb id=\"correct_data_format\"\u003eCorrect data format\u003c/b\u003e\u003c/h3\u003e\n","\u003cp\u003eThis step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).\u003c/p\u003e\n","\n","In Pandas, we use:\n","\n","\u003cp\u003e\u003cb\u003e.dtype()\u003c/b\u003e to check the data type\u003c/p\u003e\n","\u003cp\u003e\u003cb\u003e.astype()\u003c/b\u003e to change the data type\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"59cad9b5-4d0e-4474-ae08-4b093f2e5e2b","metadata":{},"outputs":[],"source":["Let's list the data types for each column:\n"]},{"cell_type":"code","id":"d44bbe45-89f6-44a9-8fa3-62b2bcb649b5","metadata":{},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","id":"7568ceba-4822-456e-8530-c9d95ecf634b","metadata":{},"outputs":[],"source":["\u003cp\u003eAs we can see above, some columns are not of the correct data type. Group and SKU are categorical variables, so instead of \"object\" these have to be \"category\" type. Column \"Date\" has type \"int64\", but it's better to convert it to \"datetime\". We have to convert data types into a proper format for uncorrect column using the \u003ccode\u003eastype()\u003c/code\u003e method.\u003c/p\u003e \n"]},{"cell_type":"markdown","id":"2294b9f6-f660-4f45-8ef8-836d22be506f","metadata":{},"outputs":[],"source":["* **Convert data type of \"Date\" column**\u003c/br\u003e\n","We need to transform data type in \"Date\" column from \u003ccode\u003eint64\u003c/code\u003e to \u003ccode\u003edatetime\u003c/code\u003e. We have information only about year and month, so day doesn't matter.\n"]},{"cell_type":"code","id":"79c11c25-99b4-4ff4-b688-8a70a8fb612a","metadata":{},"outputs":[],"source":["df[\"Date\"] = pd.to_datetime(df[\"Date\"], format = \"%Y%m\")"]},{"cell_type":"markdown","id":"57c64274-458d-49e5-9629-077e13165294","metadata":{},"outputs":[],"source":["Great, now \"Date\" column has correct look.\n"]},{"cell_type":"markdown","id":"695beac8-3a1a-454b-be2b-af489258e0b5","metadata":{},"outputs":[],"source":["* **Convert data type of \"Group\" and \"SKU\" column**\u003c/br\u003e\n","Next, we want to transform our \"Group\" and \"SKU\" data type from object to category. We'll use \u003ccode\u003e.astype()\u003c/code\u003e method.\n"]},{"cell_type":"code","id":"f39499d1-6e8e-4ba0-82e4-718c6d888b26","metadata":{},"outputs":[],"source":["df[\"Group\"].unique()"]},{"cell_type":"code","id":"b06b33d3-41b3-4969-b9f2-e3452f64d502","metadata":{},"outputs":[],"source":["df[\"Group\"].nunique()"]},{"cell_type":"code","id":"e6d3331c-61d2-45c1-a83d-4394cba4ee59","metadata":{},"outputs":[],"source":["df[\"SKU\"].unique()"]},{"cell_type":"code","id":"3e845c9e-d689-455b-9b89-ee5a1409444a","metadata":{},"outputs":[],"source":["df[\"SKU\"].nunique()"]},{"cell_type":"markdown","id":"5b2d9e58-12f2-42f9-849d-16a2e761afd1","metadata":{},"outputs":[],"source":["As we can see, there are 25 values of \"Group\" and 188 values of \"SKU\", so it'll be good idea to turn their data type to categorical.\n"]},{"cell_type":"code","id":"9fe2ba14-0c2d-4905-8531-5873d90445fc","metadata":{},"outputs":[],"source":["df[[\"Group\"]] = df[[\"Group\"]].astype(\"category\")\ndf[[\"SKU\"]] = df[[\"SKU\"]].astype(\"category\")"]},{"cell_type":"code","id":"9395cd39-a939-4cdf-b4ea-0380c80b9dfe","metadata":{},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","id":"07e2e55f-019d-4281-af0c-76447cbcd459","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","id":"b4d8a8af-e4fe-479a-b406-df54193cb7c9","metadata":{},"outputs":[],"source":["\u003cb\u003eWonderful!\u003c/b\u003e\n","\n","Now we have finally obtained the cleaned dataset with no missing values with all data in its proper format.\n"]},{"cell_type":"markdown","id":"86e03060-26be-41d5-9196-c96005630dc6","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"add_group_sort\"\u003eAdding new column, grouping and sorting data\u003c/b\u003e\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"d2000964-5a61-4206-b923-4db7ad731725","metadata":{},"outputs":[],"source":["* **Adding new column**\u003c/br\u003e\n","For our future calculations it will be convenient to have a new column that shows us turnover per month.\u003c/br\u003e The formula is: **Turnover per month = Average price per package * Total package sales per month**\n"]},{"cell_type":"code","id":"dc9cb4f1-5982-4446-9d74-352e3bdb5bd0","metadata":{},"outputs":[],"source":["df[\"Turnover per month\"] = df[\"Avg Price Pkg\"] * df[\"Sales Pkg\"]\ndf.head(5)"]},{"cell_type":"markdown","id":"c3dfb56b-a1a5-47a4-985a-5bc70a24a029","metadata":{},"outputs":[],"source":["* **Grouping data**\u003c/br\u003e\n","The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables, and analysis is performed on the individual groups.\u003c/br\u003e\n","The reason for grouping data is to see, for example, total turnover by year or average turnover by month etc.\n"]},{"cell_type":"markdown","id":"82603227-f562-4088-8781-0f579673194f","metadata":{},"outputs":[],"source":["1. Let's group our turnover values by year and month:\n"]},{"cell_type":"markdown","id":"90c44609-55e2-42dc-b355-aa139b75cc09","metadata":{},"outputs":[],"source":["We group data by year and month columns, and then we show summary value of grouped turnover. \n"]},{"cell_type":"code","id":"2ed1d140-d111-4d3e-89ce-5ac38305c8e3","metadata":{},"outputs":[],"source":["result1 = df.groupby([df['Date'].dt.year, df['Date'].dt.month])['Turnover per month'].sum()\nresult1"]},{"cell_type":"markdown","id":"38b23b03-5e88-4be0-b20d-7b6a3234f008","metadata":{},"outputs":[],"source":["Let's make this table looks more convenient to see. For this we'll use \u003ccode\u003epivot_table()\u003c/code\u003e method.\n"]},{"cell_type":"code","id":"3611a506-c42b-46d3-8ade-057af1e21358","metadata":{},"outputs":[],"source":["pivot1 = pd.pivot_table(df, values=\"Turnover per month\", index=df['Date'].dt.month, columns=df['Date'].dt.year, aggfunc=\"sum\")\npivot1.index.names = [\"Month\"]\npivot1.columns.names = [\"Turnover\"]\npivot1"]},{"cell_type":"markdown","id":"f46e6d73-d528-4512-a51c-64026a58f124","metadata":{},"outputs":[],"source":["Let's use a heat map to visualize the relationship between Turnover vs Date.\n"]},{"cell_type":"code","id":"d67190e6-c6de-42e8-8c9c-8ee9165f0d62","metadata":{},"outputs":[],"source":["%matplotlib inline\nplt.pcolor(pivot1, cmap='RdBu')\nplt.colorbar()\nplt.show()"]},{"cell_type":"markdown","id":"c6f51bb1-1b9e-4284-b080-98344cbbe5df","metadata":{},"outputs":[],"source":["The heatmap plots the target variable (turnover) proportional to colour with respect to the Month and Year on the vertical and horizontal axis, respectively. This allows us to visualize how the turnover is related to Month and Year.\u003c/br\u003e\n","For example, we can see that in December 2019 (2019-12) there was low turnover (dark red color), and we can check it using our \u003ccode\u003epivot1\u003c/code\u003e table.\n"]},{"cell_type":"markdown","id":"3ce19227-b8fa-4354-85e0-1f087fa42340","metadata":{},"outputs":[],"source":["But the default labels convey no useful information to us. Let's change that:\n"]},{"cell_type":"code","id":"aa1825cb-e002-4d41-8bf4-47d4e95e2062","metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\nim = ax.pcolor(pivot1, cmap='RdBu')\n\n# label names\nrow_names = pivot1.columns\ncol_names = pivot1.index\n\n# move ticks and labels to the center\nax.set_xticks(np.arange(pivot1.shape[1]) + 0.5, minor=False)\nax.set_yticks(np.arange(pivot1.shape[0]) + 0.5, minor=False)\n\n# set names\nax.set_xticklabels(row_names, minor=False)\nax.set_yticklabels(col_names, minor=False)\n\nfig.colorbar(im)\nplt.show()"]},{"cell_type":"markdown","id":"b3f2bcc1-f66d-4ae5-b9e5-0c9cc896dfb2","metadata":{},"outputs":[],"source":["Visualization is very important in data science, and Python visualization packages provide great freedom. We will go more in-depth in a separate Python visualizations course.\n"]},{"cell_type":"markdown","id":"d06e7310-9eb6-4fd2-a726-8809a574aa74","metadata":{},"outputs":[],"source":["2. Let's group our turnover values by year and name of group:\n"]},{"cell_type":"code","id":"4b0654e6-1d6b-4003-b53f-91a63e9e218e","metadata":{},"outputs":[],"source":["result2 = df.groupby([df[\"Date\"].dt.year, \"Group\"])\nresult2[\"Turnover per month\"].sum()"]},{"cell_type":"markdown","id":"c2bf121e-79db-4f0d-a658-eb658e997c61","metadata":{},"outputs":[],"source":["Using \u003ccode\u003epivot_table\u003c/code\u003e:\n"]},{"cell_type":"code","id":"1f6ee8f0-f061-4087-8fbd-1e712bcce639","metadata":{},"outputs":[],"source":["pivot2 = pd.pivot_table(df, values=\"Turnover per month\", index=\"Group\", columns=df['Date'].dt.year, aggfunc=\"sum\")\npivot2.index.names = [\"Group of related products\"]\npivot2.columns.names = [\"Turnover per year\"]\npivot2"]},{"cell_type":"markdown","id":"dc7b3a44-2b52-4da1-9914-8c8c1d0d14ab","metadata":{},"outputs":[],"source":["3. Let's group our total package sales per month values (Sales Pkg) by year and name of group:\n"]},{"cell_type":"code","id":"705090c2-6af8-4217-857f-46d39778abdb","metadata":{},"outputs":[],"source":["result3 = df.groupby([df[\"Date\"].dt.year, \"Group\"])\nresult3[\"Sales Pkg\"].sum()"]},{"cell_type":"markdown","id":"50aded75-feea-4774-b236-848c9eb49fda","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #1:\u003c/b\u003e\n","\n","\u003cb\u003eGroup total package sales per month values (Sales Pkg) by year and name of group using \u003ccode\u003epivot_table\u003c/code\u003e function\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"bece6e99-bef9-41de-b230-697c209250b5","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"90fe960b-69e1-4988-84e1-cfa16d40edab","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","pivot3 = pd.pivot_table(df, values=\"Sales Pkg\", index=\"Group\", columns=df[\"Date\"].dt.year, aggfunc=\"sum\")\n","pivot3.index.names = [\"Group of related products\"]\n","pivot3.columns.names = [\"Total package sales per year\"]\n","pivot3\n","\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"3393d856-d9c7-4a14-982c-0c5e1729c3d9","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #2:\u003c/b\u003e\n","    \n","\u003cb\u003eGroup average turnover values by year and SKU using \u003ccode\u003egroupby()\u003c/code\u003e function\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"e5c29ba8-c1b7-486d-9060-bc3ad2b1e015","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"dd09e9f2-f7b7-4012-8546-9456b4fd7160","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","result4 = df.groupby([df[\"Date\"].dt.year, \"SKU\"])\n","result4[\"Turnover per month\"].mean()\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"ae18a25e-e2b7-4a6d-a28e-049d92e8fd7a","metadata":{},"outputs":[],"source":["* **Sorting data**\u003c/br\u003e\n","   Firstly, we'll sort by groups (A, B, C...)\u003c/br\u003e\n","   Secondly, by years (from 2022 to 2018)\n"]},{"cell_type":"code","id":"080c9907-8463-48d3-a1dd-985ee058c89d","metadata":{},"outputs":[],"source":["df1 = df.sort_values(by=[\"Group\", \"Date\"], ascending=[True, False])\ndf1.head()"]},{"cell_type":"markdown","id":"82d4c636-322c-44b5-bc57-caaa19a725c8","metadata":{},"outputs":[],"source":["We typed \u003ccode\u003eascending=[True, False]\u003c/code\u003e because we needed to sort \"Group\" column from A to Z (ascendingly) and \"Date\" column from 2022 to 2018 (descendingly).\n"]},{"cell_type":"markdown","id":"c1a5c235-f518-4b9b-8a90-c734501f4a24","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"data_standardization\"\u003eData Standardization\u003c/b\u003e\u003c/h2\u003e\n","\u003cp\u003e\n","Data is usually collected from different agencies in different formats.\n","(Data standardization is also a term for a particular type of data normalization where we subtract the mean and divide by the standard deviation.)\n","\u003c/p\u003e\n","\n","\u003cb\u003eWhat is standardization?\u003c/b\u003e\n","\n","\u003cp\u003eStandardization is the process of transforming data into a common format, allowing the researcher to make the meaningful comparison.\n","\u003c/p\u003e\n","\n","\u003cb\u003eExample\u003c/b\u003e\n","\n","Let's focus on the \"Date\" column. We have changed data type of this column so far, but as you might see, there were also days of the month (\"2018-01-01\"). We don't have information about days, only months and years, so why it may seem quite confusing. So now let's remove the day value from the \"Date\" column.\n"]},{"cell_type":"markdown","id":"a8d6b416-80bf-438b-87b2-7553269705b7","metadata":{},"outputs":[],"source":["**Attention!** \u003c/br\u003eIf you run this code, you'll get Date column in a proper way like \"2018-01\" but Date type will become string type, so you won't be able to use functions \u003ccode\u003e.dt.month\u003c/code\u003e for example. \n"]},{"cell_type":"code","id":"53d90f4e-e046-4aa3-8e98-254ec55a33eb","metadata":{},"outputs":[],"source":["# df[\"Date\"] = df[\"Date\"].dt.strftime('%Y-%m')\n# df.head()"]},{"cell_type":"markdown","id":"3246e863-accd-477b-8cab-875227a039e5","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"data_normalization\"\u003eData Normalization\u003c/b\u003e\u003c/h2\u003e\n","\n","\u003cb\u003eWhat's normalization?\u003c/b\u003e\n","\n","\u003cp\u003eNormalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the variable so the variable values range from 0 to 1.\u003cbr\u003e\n","The main goal of normalization is to bring all variables into the same range, so that no single variable dominates the analysis.\n","\u003c/p\u003e\n","\n","\u003cb\u003eWhy normalization?\u003c/b\u003e\n","\n","Imagine a huge spread of data, for instance, price may vary from very little to very high and if we want to compare them, it would be difficult to do, especially when you'll want to visualize them. So normalizing the data can help bring them to a common scale, making it easier to compare and analyze the data.\n","\n","\u003cb\u003eExample\u003c/b\u003e\n","\n","\u003cp\u003eTo demonstrate normalization, let's say we want to scale the columns \"Units Pkg\", \"Avg Price Pkg\", \"Sales Pkg\" and \"Turnover per month\".\u003c/p\u003e\n","\u003cp\u003e\u003cb\u003eTarget:\u003c/b\u003e would like to normalize those variables so their value ranges from 0 to 1.\u003c/p\u003e\n","\u003cp\u003e\u003cb\u003eApproach:\u003c/b\u003e replace original value by (original value)/(maximum value)\u003c/p\u003e\n"]},{"cell_type":"code","id":"7c127745-b488-4bdf-aef3-26abd695c5e0","metadata":{},"outputs":[],"source":["# replace (original value) by (original value)/(maximum value) in copy df\ndf1 = df.copy()\ndf1['Units Pkg Normalized'] = df['Units Pkg'] / df['Units Pkg'].max()\ndf1['Avg Price Pkg Normalized'] = df['Avg Price Pkg'] / df['Avg Price Pkg'].max()\n\ndf1[[\"Units Pkg Normalized\", \"Avg Price Pkg Normalized\"]].head()"]},{"cell_type":"markdown","id":"997a470b-dd2d-4993-a45f-26eb07b5c2a9","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #3:\u003c/b\u003e\n","\n","\u003cb\u003eAccording to the example above, normalize the columns \"Sales Pkg\" and \"Turnover per month\".\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"d5f6e252-d296-43e5-8027-d329a62c220e","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"e5aa6cfa-edb5-4541-bcff-fc15c329f6be","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","df1['Sales Pkg Normalized'] = df['Sales Pkg'] / df['Sales Pkg'].max()\n","df1['Turnover per month Normalized'] = df['Turnover per month'] / df['Turnover per month'].max() \n","\n","# show the scaled columns\n","df1[[\"Sales Pkg Normalized\", \"Turnover per month Normalized\"]].head()\n","\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"45afd947-c66a-4e3a-aa4b-2c35b032a679","metadata":{},"outputs":[],"source":["Here we can see we've normalized \"Units Pkg\", \"Avg Price Pkg\", \"Sales Pkg\" and \"Turnover per month\" in the range of \\[0,1].\n"]},{"cell_type":"markdown","id":"dcf8b0d9-7806-40a6-9155-513b9252681e","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4:\u003c/b\u003e\n","\n","\u003cb\u003eCan you normalize the same columns using built-in function?\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"dd52d547-3bfa-4815-b090-22799fdd6aa7","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"a15deada-3df5-4296-b64d-0c5dd12f48ce","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for hint\u003c/summary\u003e\n","    Another way to do it is to use \u003ccode\u003esklearn.preprocessing.normalize\u003c/code\u003e function from scikit-learn library.\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"eeca49eb-981f-4759-a6ed-3e15620e6e36","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","from sklearn.preprocessing import normalize\n","\n","df1[\"Units Pkg Normalized\"] = normalize(df[\"Units Pkg\"].values.reshape(-1, 1), norm=\"max\", axis=0, copy=False)\n","df1[\"Avg Price Pkg Normalized\"] = normalize(df[\"Avg Price Pkg\"].values.reshape(-1, 1), norm=\"max\", axis=0, copy=False)\n","\n","df1.head()\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"fe0a18a4-f7f3-46cb-83b3-462114569e27","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for explanation\u003c/summary\u003e\n","norm field means way to normalize, for example, norm='l2' corresponds to the Euclidean normalization, while norm=\"max\" corresponds for maximum normalization, like we implemented before. axis=0 corresponds to column-wise normalization. If axis=1, row-wise normalization is performed. \n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"1e902aa8-df9e-4b1a-b7af-1e0f7ecafa95","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"binning\"\u003eBinning\u003c/b\u003e\u003c/h2\u003e\n","\u003cb\u003eWhy binning?\u003c/b\u003e\n","\u003cp\u003e\n","    Binning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.\n","\u003c/p\u003e\n","\n","\u003cb\u003eExample: \u003c/b\u003e\n","\n","\u003cp\u003eIn our dataset, \"Avg Price Pkg\" is a real valued variable ranging from 2 to 26 and it has 19 unique values. (we can check this using \u003ccode\u003edf[\"Avg Price Pkg\"].unique()\u003c/code\u003e What if we only care about high average price, medium average price and low average price? (3 types) Can we rearrange them into three ‘bins' to simplify analysis? \u003c/p\u003e\n","\n","\u003cp\u003eWe will use the pandas method 'cut' to segment the 'Avg Price Pkg' column into 3 bins.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"3542268b-2ea1-4884-a959-1d85dc9421e7","metadata":{},"outputs":[],"source":["\u003ch3\u003e\u003cb\u003eExample of Binning Data In Pandas\u003c/b\u003e\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"866305b7-52a5-48e2-acfe-e81e9938bdda","metadata":{},"outputs":[],"source":["Let's plot the histogram of turnover to see what the distribution of turnover per month looks like.\n"]},{"cell_type":"code","id":"b7d14bbd-5e28-4228-b84b-78af60170165","metadata":{},"outputs":[],"source":["import matplotlib as plt\nfrom matplotlib import pyplot\n\nplt.pyplot.hist(df[\"Avg Price Pkg\"])\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg Price Pkg\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Average Price bins\")"]},{"cell_type":"markdown","id":"44567195-4093-49d2-bcd5-a0d51a73dc41","metadata":{},"outputs":[],"source":["\u003cp\u003eWe would like 3 bins of equal size bandwidth so we use numpy's \u003ccode\u003elinspace(start_value, end_value, numbers_generated)\u003c/code\u003e function.\u003c/p\u003e\n","\u003cp\u003eSince we want to include the minimum value of turnover per month, we want to set \u003ccode\u003estart_value = min(df[\"Turnover per month\"])\u003c/code\u003e.\u003c/p\u003e\n","\u003cp\u003eSince we want to include the maximum value of turnover per month, we want to set \u003ccode\u003eend_value = max(df[\"Turnover per month\"])\u003c/code\u003e.\u003c/p\u003e\n","\u003cp\u003eSince we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated = 4.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"c28fb134-5bac-434f-8cbc-5b8fc72dd431","metadata":{},"outputs":[],"source":["We build a bin array with a minimum value to a maximum value by using the bandwidth calculated above. The values will determine when one bin ends and another begins.\n"]},{"cell_type":"code","id":"2d876525-3b5c-4f9e-95fe-cbfbaea4bc5a","metadata":{},"outputs":[],"source":["bins = np.linspace(min(df[\"Avg Price Pkg\"]), max(df[\"Avg Price Pkg\"]), 4)\nbins"]},{"cell_type":"markdown","id":"db6cbe70-aa29-4f6e-9794-53bf6e85ac2b","metadata":{},"outputs":[],"source":["We set group  names:\n"]},{"cell_type":"code","id":"9f61c0ff-942e-477f-b268-3974c2fc4f2c","metadata":{},"outputs":[],"source":["group_names = ['Low', 'Medium', 'High']"]},{"cell_type":"markdown","id":"3d15a696-d3e2-4174-91b7-0be0210cc00b","metadata":{},"outputs":[],"source":["We apply the function \"cut\" to determine what each value of `df['Turnover per month']` belongs to.\n"]},{"cell_type":"code","id":"29408153-b14d-4a1b-b501-15e8f9157575","metadata":{},"outputs":[],"source":["df['Avg Price Pkg binned'] = pd.cut(df['Avg Price Pkg'], bins, labels=group_names, include_lowest=True )\ndf[['Avg Price Pkg','Avg Price Pkg binned']].head(15)"]},{"cell_type":"markdown","id":"91a22f38-7bd9-4e12-86ab-2124a9ca8a7d","metadata":{},"outputs":[],"source":["Let's see the number of vehicles in each bin:\n"]},{"cell_type":"code","id":"be3f5238-d5a4-45fd-b4db-f6608d46e52f","metadata":{},"outputs":[],"source":["df[\"Avg Price Pkg binned\"].value_counts()"]},{"cell_type":"markdown","id":"0dc7beda-b5f3-4bb6-a67c-e68a3da1c665","metadata":{},"outputs":[],"source":["Let's plot the distribution of each bin:\n"]},{"cell_type":"code","id":"74dca7d5-5a1c-4463-b8a2-e8c443c878a6","metadata":{},"outputs":[],"source":["pyplot.bar(group_names, df[\"Avg Price Pkg binned\"].value_counts())\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg Price Pkg\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Average price bins\")"]},{"cell_type":"markdown","id":"4bc5c990-5483-43a7-b821-59da4075ac35","metadata":{},"outputs":[],"source":["\u003cp\u003e\n","    Look at the dataframe above carefully. You will find that the last column provides the bins for average price based on 3 categories (\"Low\", \"Medium\" and \"High\"). \n","\u003c/p\u003e\n","\u003cp\u003e\n","    We successfully narrowed down the intervals from 19 to 3!\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"20ca6a8d-488e-4a6c-9621-4229625b3e50","metadata":{},"outputs":[],"source":["\u003ch3\u003e\u003cb\u003eBins Visualization\u003c/b\u003e\u003c/h3\u003e\n","Normally, a histogram is used to visualize the distribution of bins we created above. \n"]},{"cell_type":"code","id":"6500ea34-b618-4937-92c5-d416bb53a063","metadata":{},"outputs":[],"source":["# draw historgram of attribute \"Turnover per month\" with bins = 3\nplt.pyplot.hist(df[\"Avg Price Pkg\"], bins = 3)\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg Price Pkg\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Average price bins\")"]},{"cell_type":"markdown","id":"ceae13da-b4de-4ffc-8619-ebbc6d6dcf02","metadata":{},"outputs":[],"source":["The plot above shows the binning result for the attribute \"Avg Price Pkg\".\n"]},{"cell_type":"markdown","id":"2b77585f-48b7-4200-9cfa-3270cee43b17","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #5:\u003c/b\u003e\n","\n","\u003cb\u003eBin column \"Sales Pkg\" and visualize it.\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"672106f6-eb09-47fa-bf0a-386993535128","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"cd16415b-4a70-4b62-93fa-f666e32a04c2","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# to see distribution of total package sales\n","plt.pyplot.hist(df[\"Sales Pkg\"])\n","plt.pyplot.xlabel(\"Sales Pkg\")\n","plt.pyplot.ylabel(\"count\")\n","plt.pyplot.title(\"Total package sales\")\n","\n","# divide to 3 bins\n","bins_sales = np.linspace(min(df[\"Sales Pkg\"]), max(df[\"Sales Pkg\"]), 4)\n","bins_sales\n","\n","# give a name\n","df[\"Sales Pkg binned\"] = pd.cut(df[\"Sales Pkg\"], bins_sales, labels=group_names, include_lowest=True)\n","df[[\"Sales Pkg binned\", \"Sales Pkg\"]].head()\n","\n","# visualize binned\n","plt.pyplot.bar(group_names, df[\"Sales Pkg binned\"].value_counts())\n","plt.pyplot.xlabel(\"Sales Pkg bins\")\n","plt.pyplot.ylabel(\"count\")\n","plt.pyplot.title(\"Total package sales\")\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"562efa9d-7a83-468a-b281-49fe68fd7a51","metadata":{},"outputs":[],"source":["\u003ch2\u003e\u003cb id=\"indicator\"\u003eIndicator Variable (or Dummy Variable)\u003c/b\u003e\u003c/h2\u003e\n","\u003cb\u003eWhat is an indicator variable?\u003c/b\u003e\n","\u003cp\u003e\n","    An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. \n","\u003c/p\u003e\n","\n","\u003cb\u003eWhy we use indicator variables?\u003c/b\u003e\n","\n","\u003cp\u003e\n","    We use indicator variables so we can use categorical variables for regression analysis in the later modules.\n","\u003c/p\u003e\n","\u003cb\u003eExample\u003c/b\u003e\n","\u003cp\u003e\n","    We see the column \"Avg Price Pkg binned\" has 3 unique values. Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"Avg Price Pkg binned\" to indicator variables.\n","\u003c/p\u003e\n","\n","\u003cp\u003e\n","    We will use pandas' method \u003ccode\u003eget_dummies\u003c/code\u003e to assign numerical values to different categories of \"Avg Price Pkg binned\". \n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"ed3177df-7877-41ab-af5b-62c1ae6bb19a","metadata":{},"outputs":[],"source":["df[\"Avg Price Pkg binned\"].unique()"]},{"cell_type":"code","id":"8664de8c-e7ef-4639-b7de-c95297772703","metadata":{},"outputs":[],"source":["df[\"Avg Price Pkg binned\"].nunique()"]},{"cell_type":"code","id":"874d9671-72ec-42f4-b81b-201c119859ec","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","id":"0c40f85a-fe45-43df-9f6b-c94887b82ac5","metadata":{},"outputs":[],"source":["Get the indicator variables and assign it to data frame \"dummy_variable\\_1\":\n"]},{"cell_type":"code","id":"92e87d3e-d413-4633-a365-e9f4da68fa8b","metadata":{},"outputs":[],"source":["dummy_variable = pd.get_dummies(df[\"Avg Price Pkg binned\"])\ndummy_variable.head()"]},{"cell_type":"markdown","id":"7493baf3-b07e-44c2-9bf6-ad30c76cc5d2","metadata":{},"outputs":[],"source":["We can get data at certain indexes:\n"]},{"cell_type":"code","id":"6dfb2803-f920-4414-b4e0-ea8100387555","metadata":{},"outputs":[],"source":["dummy_variable.loc[765:]"]},{"cell_type":"markdown","id":"c32194f2-e33b-432f-bab2-c1e8528de0c8","metadata":{},"outputs":[],"source":["Or we can get, for instance, data about high turnover:\n"]},{"cell_type":"code","id":"23dc7cc9-3cbf-429c-9aa8-b1b16386367b","metadata":{},"outputs":[],"source":["dummy_variable[dummy_variable[\"High\"] == 1]"]},{"cell_type":"markdown","id":"0932e49d-fb4b-45b9-9ffe-6060dae7a269","metadata":{},"outputs":[],"source":["Change the column names for clarity:\n"]},{"cell_type":"code","id":"928e2cad-67be-4c11-98f1-c3a9ddb1f07e","metadata":{},"outputs":[],"source":["dummy_variable.rename(columns={'Low':'Low avg price', 'Medium':'Medium avg price', \"High\" : \"High avg price\"}, inplace=True)\ndummy_variable.head()"]},{"cell_type":"code","id":"599f7be9-0bc2-4c0c-9170-3930c1bfb9d9","metadata":{},"outputs":[],"source":["# merge data frame \"df\" and \"dummy_variable_1\" \ndf = pd.concat([df, dummy_variable], axis=1)\n\n# drop original column \"Turnover per month binned\" from \"df\"\n# df.drop(\"Turnover per month binned\", axis=1, inplace=True)"]},{"cell_type":"markdown","id":"80c7e20e-afd5-4b66-8213-9144ad9f5cea","metadata":{},"outputs":[],"source":["Note: you can delete \"Turnover per month binned\", but if you want to rerun code of distribution of each bin you must restart kernel.\n"]},{"cell_type":"code","id":"939ae5b3-2e71-4451-b719-d33d9e9abdbc","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","id":"ff02d955-577e-4ad7-84ad-ec50fa62bb6b","metadata":{},"outputs":[],"source":["The last three columns are now the indicator variable representation of the \"Avg Price Pkg binned\" variable. They're all 0s and 1s now.\n"]},{"cell_type":"markdown","id":"4bf322c0-9e2a-4935-a497-c2cc5b95924d","metadata":{},"outputs":[],"source":["**Save the new csv**\n"]},{"cell_type":"code","id":"6cc6602f-f535-4de7-ab2a-38a1675dcbbd","metadata":{},"outputs":[],"source":["df.to_csv('clean_sales_1.csv', index=False)"]},{"cell_type":"markdown","id":"fe66fe73-7d50-4970-adb7-3642ab1e589f","metadata":{},"outputs":[],"source":["\u003e Note : The  csv file cannot be viewed in the jupyterlite based SN labs environment.However you can Click \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%202/DA0101EN-2-Review-Data-Wrangling.ipynb?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2022-01-01\"\u003eEDIT WHEN PUBLISH LAB 2!!!!!!!!!!!!!!!!\u003c/a\u003e to download the lab notebook (.ipynb) to your local machine and view the csv file once the notebook is executed.\n"]},{"cell_type":"markdown","id":"047e400a-0d14-4fc3-a150-8101a04c821c","metadata":{},"outputs":[],"source":["### **Thank you for completing this lab!**\n","\n","## Authors\n","\n","\u003ca href=\"https://author.skills.network/instructors/rosana_klym?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\"\u003eRosana Klym\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\"\u003eYaroslav Vyklyuk\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/olga_kavun?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\"\u003eOlga Kavun\u003c/a\u003e\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                  |\n","| ----------------- | ------- | ---------- | ----------------------------------- |\n","| 2023-05-19        | 1.0     | Rosana     | Anchor links works\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2023. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}