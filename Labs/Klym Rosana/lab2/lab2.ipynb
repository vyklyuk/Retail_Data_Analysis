{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n",
    "\n",
    "# **Retail Sales Dataset 2018-2022**\n",
    "\n",
    "## **Lab 2. Data Wrangling**\n",
    "\n",
    "Estimated time needed: **30** minutes\n",
    "\n",
    "### **Dataset Attributes**\n",
    "*   Date: year and month\n",
    "*   SKU: unique code consisting of letters and numbers that identify each product\n",
    "*   Group: group of related products which share some common attributes\n",
    "*   Units Pkg: package weight (kg)\n",
    "*   Avg Price Pkg: average price per package\n",
    "*   Sales Pkg: total package sales per month\n",
    "\n",
    "### **Target Field**\n",
    "*   Turnover per month\n",
    "\n",
    "## **Objectives**\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   Detect and handle missing values\n",
    "*   Correct data format\n",
    "*   Standardize and normalize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li><a href=\"https://#identify_handle_missing_values\">Identify and handle missing values</a>\n",
    "        <ul>\n",
    "            <li><a href=\"https://#identify_missing_values\">Identify missing values</a></li>\n",
    "            <li><a href=\"https://#deal_missing_values\">Deal with missing values</a></li>\n",
    "            <li><a href=\"https://#correct_data_format\">Correct data format</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a href=\"https://#data_standardization\">Data standardization</a></li>\n",
    "    <li><a href=\"https://#data_normalization\">Data normalization (centering/scaling)</a></li>\n",
    "    <li><a href=\"https://#binning\">Binning</a></li>\n",
    "    <li><a href=\"https://#indicator\">Indicator variable</a></li>\n",
    "</ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What is the purpose of data wrangling?**\n",
    "Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Data**\n",
    "<p>\n",
    "You can find the \"Retail Sales Dataset 2018-2022\" from the following link: <a href=\"https://www.kaggle.com/datasets/tsmldata/retail-sales-dataset-2018-2022?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\">https://www.kaggle.com/datasets/tsmldata/retail-sales-dataset-2018-2022</a>. \n",
    "We will be using this dataset throughout this course.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import pandas**\n",
    "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n",
    "#install specific version of libraries used in lab\n",
    "#! mamba install pandas==1.3.3\n",
    "#! mamba install numpy=1.21.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reading the dataset from the URL**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we assign the URL of the dataset to \"filename\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0OWKEN/sales_1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Pandas method <b>read_csv()</b> to load the data from the web address. Set the parameter  \"names\" equal to the Python list \"headers\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method <b>head()</b> to display the first five rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what the data set looks like, we'll use the head() method.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are any uncorrect values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there are no uncorrect values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"identify_missing_values\"><b>Identify missing values</b></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluating for Missing Data**\n",
    "\n",
    "The missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n",
    "\n",
    "<ol>\n",
    "    <li><b>.isnull()</b></li>\n",
    "    <li><b>.notnull()</b></li>\n",
    "</ol>\n",
    "The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull()\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Count missing values in each column</b></h4>\n",
    "<p>\n",
    "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method <code>value_counts()</code> counts the number of \"True\" values. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary above, each column has 4138 rows of data and there are no columns that contain missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"correct_data_format\"><b>Correct data format</b></h3>\n",
    "<p>This step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).</p>\n",
    "\n",
    "In Pandas, we use:\n",
    "\n",
    "<p><b>.dtype()</b> to check the data type</p>\n",
    "<p><b>.astype()</b> to change the data type</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's list the data types for each column</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can see above, some columns are not of the correct data type. Group and SKU are categorical variables, so instead of \"object\" these have to be \"category\" type. Column \"Date\" has type \"int64\", but it's better to convert it to \"datetime\". We have to convert data types into a proper format for uncorrect column using the <code>astype()</code> method.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Convert data type of \"Date\" column**</br>\n",
    "We need to transform data type in \"Date\" column from <code>int64</code> to <code>datetime</code>. We have information only about year and month, so day doesn't matter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format = \"%Y%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now \"Date\" column has correct look.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Convert data type of \"Group\" and \"SKU\" column**</br>\n",
    "Next, we want to transform our \"Group\" and \"SKU\" data type from object to category. We'll use <code>.astype()</code> method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Group\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SKU\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SKU\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 25 values of \"Group\" and 188 values of \"SKU\", so it'll be good idea to turn their data type to categorical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Group\"]] = df[[\"Group\"]].astype(\"category\")\n",
    "df[[\"SKU\"]] = df[[\"SKU\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Wonderful!</b>\n",
    "\n",
    "Now we have finally obtained the cleaned dataset with no missing values with all data in its proper format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adding new column, grouping and sorting data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Adding new column**</br>\n",
    "For our future calculations it will be convenient to have a new column that shows us turnover per month.</br> The formula is: **Turnover per month = Average price per package * Total package sales per month**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Turnover per month\"] = df[\"Avg Price Pkg\"] * df[\"Sales Pkg\"]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Grouping data**</br>\n",
    "The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables, and analysis is performed on the individual groups.</br>\n",
    "The reason for grouping data is to see, for example, total turnover by year or average turnover by month etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let's group our turnover values by year and month:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group data by year and month columns, and then we show summary value of grouped turnover. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = df.groupby([df['Date'].dt.year, df['Date'].dt.month])['Turnover per month'].sum()\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this table looks more convenient to see. For this we'll use <code>pivot_table()</code> method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot1 = pd.pivot_table(df, values=\"Turnover per month\", index=df['Date'].dt.month, columns=df['Date'].dt.year, aggfunc=\"sum\")\n",
    "pivot1.index.names = [\"Month\"]\n",
    "pivot1.columns.names = [\"Turnover\"]\n",
    "pivot1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a heat map to visualize the relationship between Turnover vs Date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.pcolor(pivot1, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap plots the target variable (turnover) proportional to colour with respect to the Month and Year on the vertical and horizontal axis, respectively. This allows us to visualize how the turnover is related to Month and Year.</br>\n",
    "For example, we can see that in December 2019 (2019-12) there was low turnover (dark red color), and we can check it using our <code>pivot1</code> table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the default labels convey no useful information to us. Let's change that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(pivot1, cmap='RdBu')\n",
    "\n",
    "# label names\n",
    "row_names = pivot1.columns\n",
    "col_names = pivot1.index\n",
    "\n",
    "# move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(pivot1.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(pivot1.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "# set names\n",
    "ax.set_xticklabels(row_names, minor=False)\n",
    "ax.set_yticklabels(col_names, minor=False)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization is very important in data science, and Python visualization packages provide great freedom. We will go more in-depth in a separate Python visualizations course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let's group our turnover values by year and name of group:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = df.groupby([df[\"Date\"].dt.year, \"Group\"])\n",
    "result2[\"Turnover per month\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <code>pivot_table</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2 = pd.pivot_table(df, values=\"Turnover per month\", index=\"Group\", columns=df['Date'].dt.year, aggfunc=\"sum\")\n",
    "pivot2.index.names = [\"Group of related products\"]\n",
    "pivot2.columns.names = [\"Turnover per year\"]\n",
    "pivot2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's group our total package sales per month values (Sales Pkg) by year and name of group:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = df.groupby([df[\"Date\"].dt.year, \"Group\"])\n",
    "result3[\"Sales Pkg\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "  <b style=\"font-size: 2em; font-weight: bold;\">Question #1:</b>\n",
    "\n",
    "<b>Group total package sales per month values (Sales Pkg) by year and name of group using <code>pivot_table</code> function</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "pivot3 = pd.pivot_table(df, values=\"Sales Pkg\", index=\"Group\", columns=df[\"Date\"].dt.year, aggfunc=\"sum\")\n",
    "pivot3.index.names = [\"Group of related products\"]\n",
    "pivot3.columns.names = [\"Total package sales per year\"]\n",
    "pivot3\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "  <b style=\"font-size: 2em; font-weight: bold;\">Question #2:</b>\n",
    "    \n",
    "<b>Group average turnover values by year and SKU using <code>groupby()</code> function</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "result4 = df.groupby([df[\"Date\"].dt.year, \"SKU\"])\n",
    "result4[\"Turnover per month\"].mean()\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sorting data**</br>\n",
    "   Firstly, we'll sort by groups (A, B, C...)</br>\n",
    "   Secondly, by years (from 2022 to 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sort_values(by=[\"Group\", \"Date\"], ascending=[True, False])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typed <code>ascending=[True, False]</code> because we needed to sort \"Group\" column from A to Z (ascendingly) and \"Date\" column from 2022 to 2018 (descendingly).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_standardization\"><b>Data Standardization</b></h2>\n",
    "<p>\n",
    "Data is usually collected from different agencies in different formats.\n",
    "(Data standardization is also a term for a particular type of data normalization where we subtract the mean and divide by the standard deviation.)\n",
    "</p>\n",
    "\n",
    "<b>What is standardization?</b>\n",
    "\n",
    "<p>Standardization is the process of transforming data into a common format, allowing the researcher to make the meaningful comparison.\n",
    "</p>\n",
    "\n",
    "<b>Example</b>\n",
    "\n",
    "Let's focus on the \"Date\" column. We have changed data type of this column so far, but as you might see, there were also days of the month (\"2018-01-01\"). We don't have information about days, only months and years, so why it may seem quite confusing. So now let's remove the day value from the \"Date\" column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention!** </br>If you run this code, you'll get Date column in a proper way like \"2018-01\" but Date type will become string type, so you won't be able to use functions <code>.dt.month</code> for example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Date\"] = df[\"Date\"].dt.strftime('%Y-%m')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_normalization\"><b>Data Normalization</b></h2>\n",
    "\n",
    "<b>What's normalization?</b>\n",
    "\n",
    "<p>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the variable so the variable values range from 0 to 1.<br>\n",
    "The main goal of normalization is to bring all variables into the same range, so that no single variable dominates the analysis.\n",
    "</p>\n",
    "\n",
    "<b>Why normalization?</b>\n",
    "\n",
    "Imagine a huge spread of data, for instance, price may vary from very little to very high and if we want to compare them, it would be difficult to do, especially when you'll want to visualize them. So normalizing the data can help bring them to a common scale, making it easier to compare and analyze the data.\n",
    "\n",
    "<b>Example</b>\n",
    "\n",
    "<p>To demonstrate normalization, let's say we want to scale the columns \"Units Pkg\", \"Avg Price Pkg\", \"Sales Pkg\" and \"Turnover per month\".</p>\n",
    "<p><b>Target:</b> would like to normalize those variables so their value ranges from 0 to 1.</p>\n",
    "<p><b>Approach:</b> replace original value by (original value)/(maximum value)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace (original value) by (original value)/(maximum value) in copy df\n",
    "df1 = df.copy()\n",
    "df1['Units Pkg Normalized'] = df['Units Pkg'] / df['Units Pkg'].max()\n",
    "df1['Avg Price Pkg Normalized'] = df['Avg Price Pkg'] / df['Avg Price Pkg'].max()\n",
    "\n",
    "df1[[\"Units Pkg Normalized\", \"Avg Price Pkg Normalized\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "  <b style=\"font-size: 2em; font-weight: bold;\">Question #3:</b>\n",
    "\n",
    "<b>According to the example above, normalize the columns \"Sales Pkg\" and \"Turnover per month\".</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "df1['Sales Pkg Normalized'] = df['Sales Pkg'] / df['Sales Pkg'].max()\n",
    "df1['Turnover per month Normalized'] = df['Turnover per month'] / df['Turnover per month'].max() \n",
    "\n",
    "# show the scaled columns\n",
    "df1[[\"Sales Pkg Normalized\", \"Turnover per month Normalized\"]].head()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see we've normalized \"Units Pkg\", \"Avg Price Pkg\", \"Sales Pkg\" and \"Turnover per month\" in the range of \\[0,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "  <b style=\"font-size: 2em; font-weight: bold;\">Question #4:</b>\n",
    "\n",
    "<b>Can you normalize the same columns using built-in function?</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for hint</summary>\n",
    "    Another way to do it is to use <code>sklearn.preprocessing.normalize</code> function from scikit-learn library.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "df1[\"Units Pkg Normalized\"] = normalize(df[\"Units Pkg\"].values.reshape(-1, 1), norm=\"max\", axis=0, copy=False)\n",
    "df1[\"Avg Price Pkg Normalized\"] = normalize(df[\"Avg Price Pkg\"].values.reshape(-1, 1), norm=\"max\", axis=0, copy=False)\n",
    "\n",
    "df1.head()\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for explanation</summary>\n",
    "norm field means way to normalize, for example, norm='l2' corresponds to the Euclidean normalization, while norm=\"max\" corresponds for maximum normalization, like we implemented before. axis=0 corresponds to column-wise normalization. If axis=1, row-wise normalization is performed. \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"binning\"><b>Binning</b></h2>\n",
    "<b>Why binning?</b>\n",
    "<p>\n",
    "    Binning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.\n",
    "</p>\n",
    "\n",
    "<b>Example: </b>\n",
    "\n",
    "<p>In our dataset, \"Avg Price Pkg\" is a real valued variable ranging from 2 to 26 and it has 19 unique values. (we can check this using <code>df[\"Avg Price Pkg\"].unique()</code> What if we only care about high average price, medium average price and low average price? (3 types) Can we rearrange them into three ‘bins' to simplify analysis? </p>\n",
    "\n",
    "<p>We will use the pandas method 'cut' to segment the 'Avg Price Pkg' column into 3 bins.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example of Binning Data In Pandas**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the histogram of turnover to see what the distribution of turnover per month looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "plt.pyplot.hist(df[\"Avg Price Pkg\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"Avg Price Pkg\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"Average Price bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We would like 3 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated)</code> function.</p>\n",
    "<p>Since we want to include the minimum value of turnover per month, we want to set <code>start_value = min(df[\"Turnover per month\"])</code>.</p>\n",
    "<p>Since we want to include the maximum value of turnover per month, we want to set <code>end_value = max(df[\"Turnover per month\"])</code>.</p>\n",
    "<p>Since we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated = 4.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a bin array with a minimum value to a maximum value by using the bandwidth calculated above. The values will determine when one bin ends and another begins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df[\"Avg Price Pkg\"]), max(df[\"Avg Price Pkg\"]), 4)\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set group  names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the function \"cut\" to determine what each value of `df['Turnover per month']` belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg Price Pkg binned'] = pd.cut(df['Avg Price Pkg'], bins, labels=group_names, include_lowest=True )\n",
    "df[['Avg Price Pkg','Avg Price Pkg binned']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the number of vehicles in each bin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Avg Price Pkg binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distribution of each bin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.bar(group_names, df[\"Avg Price Pkg binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"Avg Price Pkg\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"Average price bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Look at the dataframe above carefully. You will find that the last column provides the bins for average price based on 3 categories (\"Low\", \"Medium\" and \"High\"). \n",
    "</p>\n",
    "<p>\n",
    "    We successfully narrowed down the intervals from 19 to 3!\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bins Visualization**\n",
    "Normally, a histogram is used to visualize the distribution of bins we created above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw historgram of attribute \"Turnover per month\" with bins = 3\n",
    "plt.pyplot.hist(df[\"Avg Price Pkg\"], bins = 3)\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"Avg Price Pkg\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"Average price bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the binning result for the attribute \"Avg Price Pkg\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "  <b style=\"font-size: 2em; font-weight: bold;\">Question #5:</b>\n",
    "\n",
    "<b>Bin column \"Sales Pkg\" and visualize it.</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "# to see distribution of total package sales\n",
    "plt.pyplot.hist(df[\"Sales Pkg\"])\n",
    "plt.pyplot.xlabel(\"Sales Pkg\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"Total package sales\")\n",
    "\n",
    "# divide to 3 bins\n",
    "bins_sales = np.linspace(min(df[\"Sales Pkg\"]), max(df[\"Sales Pkg\"]), 4)\n",
    "bins_sales\n",
    "\n",
    "# give a name\n",
    "df[\"Sales Pkg binned\"] = pd.cut(df[\"Sales Pkg\"], bins_sales, labels=group_names, include_lowest=True)\n",
    "df[[\"Sales Pkg binned\", \"Sales Pkg\"]].head()\n",
    "\n",
    "# visualize binned\n",
    "plt.pyplot.bar(group_names, df[\"Sales Pkg binned\"].value_counts())\n",
    "plt.pyplot.xlabel(\"Sales Pkg bins\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"Total package sales\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"indicator\"><b>Indicator Variable (or Dummy Variable)</b></h2>\n",
    "<b>What is an indicator variable?</b>\n",
    "<p>\n",
    "    An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. \n",
    "</p>\n",
    "\n",
    "<b>Why we use indicator variables?</b>\n",
    "\n",
    "<p>\n",
    "    We use indicator variables so we can use categorical variables for regression analysis in the later modules.\n",
    "</p>\n",
    "<b>Example</b>\n",
    "<p>\n",
    "    We see the column \"Avg Price Pkg binned\" has 3 unique values. Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"Avg Price Pkg binned\" to indicator variables.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    We will use pandas' method <code>get_dummies</code> to assign numerical values to different categories of \"Avg Price Pkg binned\". \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Avg Price Pkg binned\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Avg Price Pkg binned\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the indicator variables and assign it to data frame \"dummy_variable\\_1\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable = pd.get_dummies(df[\"Avg Price Pkg binned\"])\n",
    "dummy_variable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get data at certain indexes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable.loc[765:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can get, for instance, data about high turnover:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable[dummy_variable[\"High\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the column names for clarity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable.rename(columns={'Low':'Low avg price', 'Medium':'Medium avg price', \"High\" : \"High avg price\"}, inplace=True)\n",
    "dummy_variable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable], axis=1)\n",
    "\n",
    "# drop original column \"Turnover per month binned\" from \"df\"\n",
    "# df.drop(\"Turnover per month binned\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can delete \"Turnover per month binned\", but if you want to rerun code of distribution of each bin you must restart kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three columns are now the indicator variable representation of the \"Avg Price Pkg binned\" variable. They're all 0s and 1s now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the new csv**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_sales_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : The  csv file cannot be viewed in the jupyterlite based SN labs environment.However you can Click <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%202/DA0101EN-2-Review-Data-Wrangling.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2022-01-01\">EDIT WHEN PUBLISH LAB 2!!!!!!!!!!!!!!!!</a> to download the lab notebook (.ipynb) to your local machine and view the csv file once the notebook is executed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Thank you for completing this lab!**\n",
    "\n",
    "## Authors\n",
    "\n",
    "<a href=\"https://author.skills.network/instructors/rosana_klym?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\">Rosana Klym</a>\n",
    "\n",
    "<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\">Yaroslav Vyklyuk</a>\n",
    "\n",
    "<a href=\"https://author.skills.network/instructors/olga_kavun?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0OWKEN2680-2023-01-01\">Olga Kavun</a>\n",
    "\n",
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                  |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------- |\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
