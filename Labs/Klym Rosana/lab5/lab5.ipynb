{"cells":[{"cell_type":"markdown","id":"fe68ad11-bc25-4e8a-927a-2f468abd8134","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","# **Retail Sales Dataset 2018-2022**\n","# **Lab 5. Model Evaluation and Refinement**\n","\n","Estimated time needed: **1** hour\n","\n","### **Dataset Attributes**\n","*   Date: year and month\n","*   SKU: unique code consisting of letters and numbers that identify each product\n","*   Group: group of related products which share some common attributes\n","*   Units Pkg: package weight (kg)\n","*   Avg Price Pkg: average price per package\n","*   Sales Pkg: total package sales per month\n","\n","### **Target Field**\n","*   Turnover per month\n","\n","### **Objectives**\n","\n","After completing this lab you will be able to:\n","\n","*   Evaluate and refine prediction models\n"]},{"cell_type":"markdown","id":"8f32ac7d-e9ea-4ca4-bada-cb72e4751051","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#ref1\"\u003eTraining and Testing\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#ref2\"\u003eOver-fitting, Under-fitting and Model Selection \u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#ref3\"\u003eRidge Regression \u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#ref4\"\u003eGrid Search\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"1d5933ad-5386-43d4-9760-cc1088789e55","metadata":{},"outputs":[],"source":["#### **Setup**\n"]},{"cell_type":"markdown","id":"9db003d9-0a39-4bdf-b775-ea9c82f228c4","metadata":{},"outputs":[],"source":["If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"]},{"cell_type":"code","id":"14d6d92f-2abb-435d-a3f9-66b9029acf84","metadata":{},"outputs":[],"source":["#install specific version of libraries used in lab\n#! mamba install pandas -y\n#! mamba install numpy -y\n#! mamba install scikit-learn -y\n#! mamba install ipywidgets -y\n#! mamba install tqdm"]},{"cell_type":"code","id":"10877873-4742-4154-aa13-a3ef0d5b06b9","metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict"]},{"cell_type":"markdown","id":"903d5fc3-6e01-490a-862e-b791350bc45f","metadata":{},"outputs":[],"source":["Libraries for plotting:\n"]},{"cell_type":"code","id":"e5771b09-26b2-4200-9edf-eba2a3ee2573","metadata":{},"outputs":[],"source":["from ipywidgets import interact, interactive, fixed, interact_manual\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns"]},{"cell_type":"markdown","id":"29c063d7-13a5-4423-b4a8-6ccd9830d651","metadata":{},"outputs":[],"source":["This dataset was hosted on IBM Cloud object. Click \u003ca href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\"\u003eHERE\u003c/a\u003e for free storage.\n"]},{"cell_type":"code","id":"2c3ceb57-20f3-452e-ac47-ba0153e0932e","metadata":{},"outputs":[],"source":["path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX044EN/clean_sales_1.csv'\ndf = pd.read_csv(path)\ndf.head()"]},{"cell_type":"markdown","id":"6c51b955-8914-464d-b104-8d48a3964e1d","metadata":{},"outputs":[],"source":["\u003cb\u003eIn previous lab, we told that 'Sales Pkg' was an important variable for predicting turnover. Instead, she was too suspiciously good. If you wonder why, you can check in chapter 'Overfitting' that no matter polynomial order we input or size of test data we input, the model will always fit perfectly.\u003c/br\u003e\n","That's because 'Sales Pkg' is directly proportional to 'Turnover per month' because turnover = sales pkg * avg price pkg. It is impractical to give an input variable that is directly proportional to the output variable.\u003c/b\u003e\n"]},{"cell_type":"markdown","id":"55836c25-e768-4bc3-a54b-cd76231258a9","metadata":{},"outputs":[],"source":["So let's turn our categorical variables into numerical so that we can make predictions and analysis using them.\n"]},{"cell_type":"markdown","id":"136515a8-0912-4fe5-aedc-10ff8f7d2cb2","metadata":{},"outputs":[],"source":["To make 'Group' and 'Date' fields numerical:\n"]},{"cell_type":"code","id":"fa205044-5919-40b6-8026-ab6810f7f261","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OrdinalEncoder\n\nenc = OrdinalEncoder()\ndf = df[df.columns]\ndf['Group'] = enc.fit_transform(df[['Group']]).astype(int)\ndf['Date'] = enc.fit_transform(df[['Date']]).astype(int)\n\ndf.head()\n"]},{"cell_type":"markdown","id":"3725939f-13bc-4564-9b38-9cfec75b85ed","metadata":{},"outputs":[],"source":["First, let's only use numeric data:\n"]},{"cell_type":"code","id":"a90f3ce6-fe08-4d4e-89a3-ef3149f12517","metadata":{},"outputs":[],"source":["df = df._get_numeric_data()\ndf.head()"]},{"cell_type":"markdown","id":"5c9111e1-d8b2-4cd6-b3ee-6f8be34d5956","metadata":{},"outputs":[],"source":["## **Functions for Plotting**\n"]},{"cell_type":"markdown","id":"13660794-0c15-4ffb-adda-871ceb075a98","metadata":{},"outputs":[],"source":["We made similar functions in previous lab.\n"]},{"cell_type":"code","id":"fefc1349-3fa1-40dd-b479-8224f70a5026","metadata":{},"outputs":[],"source":["def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 10\n    height = 8\n    plt.figure(figsize=(width, height))\n\n    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n\n    plt.title(Title)\n    plt.xlabel('Turnover')\n    plt.ylabel('Proportion of Sales')\n\n    plt.show()\n    plt.close()"]},{"cell_type":"code","id":"4ff33c5b-ad01-4c48-9c29-7972386c2f42","metadata":{},"outputs":[],"source":["def PollyPlot(xtrain, xtest, y_train, y_test, lr, poly_transform):\n    width = 10\n    height = 8\n    plt.figure(figsize=(width, height))\n    \n    \n    #training data \n    #testing data \n    # lr:  linear regression object \n    #poly_transform:  polynomial transformation object \n \n    xmax = max([xtrain.values.max(), xtest.values.max()])\n\n    xmin = min([xtrain.values.min(), xtest.values.min()])\n\n    x = np.arange(xmin, xmax, 0.1)\n\n\n    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n    plt.plot(xtest, y_test, 'go', label='Test Data')\n    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')\n    plt.ylabel('Turnover')\n    plt.legend()"]},{"cell_type":"markdown","id":"75ce68c6-6a8d-4e9f-bbc8-5bd1b5a9b607","metadata":{},"outputs":[],"source":["\u003cdiv style=\"margin-top: 1em;\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold; text-decoration: none;\"\u003e\u003ca name=\"ref1\"\u003e\u003cfont color=\"black\"\u003ePart 1: Training and Testing\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\u003c/div\u003e\n","\n","\u003cp\u003eAn important step in testing your model is to split your data into training and testing data.\n","Training data is used to train model while testing data is used to test our model's accuracy.\u003cbr\u003e\n","We will place the target data \u003cb\u003eturnover per month\u003c/b\u003e in a separate dataframe \u003cb\u003ey_data\u003c/b\u003e:\u003c/p\u003e\n"]},{"cell_type":"code","id":"c6a6be6f-3324-4c61-9ad6-60fc5cf5f2ce","metadata":{},"outputs":[],"source":["y_data = df['Turnover per month']"]},{"cell_type":"markdown","id":"61921c05-9a31-4706-89b9-2666751bea6d","metadata":{},"outputs":[],"source":["\u003ccode\u003edf.drop()\u003c/code\u003e creates a new DataFrame x_data that contains all the columns from df except for the 'Turnover per month' column.\n"]},{"cell_type":"markdown","id":"4e898bad-78a9-4b8b-bdb6-15f0b45b6351","metadata":{},"outputs":[],"source":["Drop turnover data in dataframe **x_data**:\n"]},{"cell_type":"code","id":"6f64a363-14ee-4449-9cf2-1d36c120ff45","metadata":{},"outputs":[],"source":["x_data = df.drop('Turnover per month', axis=1)"]},{"cell_type":"markdown","id":"a78c7e0d-ac7a-4af8-891a-43e968fd04e4","metadata":{},"outputs":[],"source":["Now, we randomly split our data into training and testing data using the function \u003cb\u003etrain_test_split\u003c/b\u003e.\n"]},{"cell_type":"code","id":"c92463af-f05a-4752-b723-67fccc07bd26","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=3)\n\n\nprint(\"number of test samples :\", x_test.shape[0])\nprint(\"number of training samples:\", x_train.shape[0])"]},{"cell_type":"markdown","id":"a0453ae3-d1f2-446c-80ec-0e81f1963d0a","metadata":{},"outputs":[],"source":["x_train and y_train are the input features and target variable, respectively, for the training set, and x_test and y_test are the input features and target variable, respectively, for the test set. \n"]},{"cell_type":"markdown","id":"8e09a14f-84d1-4bd7-9b13-2279b3e8d77a","metadata":{},"outputs":[],"source":["3724 (90%) rows (observations in other words) of the data is the training data, and 414 (10%) rows (observations) is the testing data.\n"]},{"cell_type":"markdown","id":"a1e4bb22-b0f7-43e0-910d-afd7c93348f8","metadata":{},"outputs":[],"source":["The \u003cb\u003etest_size\u003c/b\u003e parameter sets the proportion of data that is split into the testing set. In the above, the testing set is 10% of the total dataset.\n"]},{"cell_type":"markdown","id":"622c2611-d564-459c-bbc2-f00bfd618327","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #1:\u003c/b\u003e\n","\n","\u003cb\u003eUse the function \"train_test_split\" to split up the dataset such that 40% of the data samples will be utilized for testing. Set the parameter \"random_state\" equal to zero. The output of the function should be the following:  \"x_train1\" , \"x_test1\", \"y_train1\" and  \"y_test1\".\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"6fdb39b4-0d8c-48f8-8f65-27d3f117ca79","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"d7b4615d-3778-4d00-93ea-f8fdebae02ae","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(x_data, y_data, test_size=0.4, random_state=0) \n","print(\"number of test samples :\", x_test1.shape[0])\n","print(\"number of training samples:\",x_train1.shape[0])\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"6ff0e5d9-47d1-4157-b694-be3b71a2cf31","metadata":{},"outputs":[],"source":["We create a Linear Regression object:\n"]},{"cell_type":"code","id":"a28f6f64-922c-4c5a-aae4-2cdcbddd2c40","metadata":{},"outputs":[],"source":["lm = LinearRegression()"]},{"cell_type":"markdown","id":"0bd1b4b1-68a7-4f1e-b32e-ccb3c2943f16","metadata":{},"outputs":[],"source":["We fit the model using the feature \"Units Pkg\":\n"]},{"cell_type":"code","id":"5bc3d05f-842e-41ea-b0f9-f1bbb0ea3702","metadata":{},"outputs":[],"source":["lm.fit(x_train[['Units Pkg']], y_train)"]},{"cell_type":"code","id":"64699a6a-e92c-40bf-a6a2-2d1eb5c86c73","metadata":{},"outputs":[],"source":["Yhat_train = lm.predict(x_train[['Units Pkg']])\nYhat_test = lm.predict(x_test[['Units Pkg']])"]},{"cell_type":"markdown","id":"80a76eb9-56a5-4fb9-b563-10fac7892c46","metadata":{},"outputs":[],"source":["Let's calculate the R^2 on the test data:\n"]},{"cell_type":"code","id":"4202c6a6-08d5-43c2-81ba-bbd40a6a8340","metadata":{},"outputs":[],"source":["lm.score(x_test[['Units Pkg']], y_test)"]},{"cell_type":"markdown","id":"9c3cf178-2b02-4931-93b3-4fe1b1bc5ba8","metadata":{},"outputs":[],"source":["We can see the R^2 is not so much bigger using the test data compared to the training data.\n"]},{"cell_type":"code","id":"2b71fcc7-4312-46c4-b932-f6aa84cb7817","metadata":{},"outputs":[],"source":["lm.score(x_train[['Units Pkg']], y_train)"]},{"cell_type":"markdown","id":"cc6af5d7-51b7-4093-9c95-55701b1a3bbf","metadata":{},"outputs":[],"source":["Our train and test r-scores are very small, it's a sign of \u003cb\u003eunderfitting\u003c/b\u003e. It means that our model doesn't fit our data.\n"]},{"cell_type":"markdown","id":"c1b9f0e2-5037-43d4-b2f4-b7728338c1be","metadata":{},"outputs":[],"source":["Let's visualize:\n"]},{"cell_type":"code","id":"dcd730f8-113a-4eee-baa5-177ef48561ec","metadata":{},"outputs":[],"source":["y_train"]},{"cell_type":"code","id":"eeba943d-a073-4502-81b7-05ca025a2127","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n\nres = pd.DataFrame(y_train)\nres['Yhat'] = Yhat_train\nres.sort_index().plot()\n\nplt.title(\"Predicted data using training data vs real value using training data\")\nplt.xlabel(\"Index of Units Pkg (X)\")\nplt.ylabel(\"Turnover (Y)\")"]},{"cell_type":"code","id":"558699e1-2199-4ce8-8d8a-d8a412e5ec9c","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\nres = pd.DataFrame(y_test)\nres['Yhat'] = Yhat_test\nres.sort_index().plot()\n\nplt.title(\"Predicted data using testing data vs real value using testing data\")\nplt.xlabel(\"Index of Units Pkg (X)\")\nplt.ylabel(\"Turnover (Y)\")"]},{"cell_type":"markdown","id":"3a5e88a9-5c2d-4c23-8d59-14a306d2e368","metadata":{},"outputs":[],"source":["It's clearly seen that our predicted data (yelow) hardly overlap our real data (blue) on both plots. \u003cb\u003eOur model didn't learn on given data\u003c/b\u003e.\n"]},{"cell_type":"markdown","id":"3ec3397e-8e8a-4a56-804d-0032df9c0621","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #2):\u003c/b\u003e\n","    \n","\u003cb\u003eFind the R^2  on the test and train data using 40% of the dataset for testing.\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"a0daa114-fe12-4440-bd1d-c237616a3f07","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"393fb110-8f85-4212-8ecc-6de5debea8be","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","x_train_ex, x_test_ex, y_train_ex, y_test_ex = train_test_split(x_data, y_data, test_size=0.4, random_state=0)\n","\n","lm_ex = LinearRegression()\n","lm_ex.fit(x_train1[['Units Pkg']], y_train1)\n","\n","print(\"r-score for test data\", lm_ex.score(x_test1[['Units Pkg']], y_test1))\n","print(\"r-score for train data\", lm_ex.score(x_train1[['Units Pkg']], y_train1))\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"b41b896f-3790-46e0-ae08-bbdc2a0b09b1","metadata":{},"outputs":[],"source":["Sometimes you do not have sufficient testing data; as a result, you may want to perform cross-validation. Let's go over several methods that you can use for cross-validation.\n"]},{"cell_type":"markdown","id":"7c4c3a11-36b9-4e19-a4c9-6e6d73d05046","metadata":{},"outputs":[],"source":["## **Cross-Validation Score**\n"]},{"cell_type":"markdown","id":"db5bce31-9ccb-4de1-8c5d-112712f29023","metadata":{},"outputs":[],"source":["We input the object, the feature (\"Units Pkg\"), and the target data (y_data).\n"]},{"cell_type":"markdown","id":"5939632b-c33f-44e3-8632-b91326a71347","metadata":{},"outputs":[],"source":["The parameter \u003ccode\u003ecv\u003c/code\u003e specifies the number of folds or partitions that the dataset will be split into. In this case, the dataset is divided into 4 parts, or folds, and the model is trained and tested 4 times, with each fold serving as the test set once and the remaining folds as the training set. The \u003ccode\u003ecross_val_score()\u003c/code\u003e function returns an array of scores, one for each fold, which can be used to evaluate the performance of the model.\n"]},{"cell_type":"code","id":"d4b426b3-cb18-4116-ac57-aea988dc2806","metadata":{},"outputs":[],"source":["Rcross = cross_val_score(lm, x_data[['Units Pkg']], y_data, cv=4)"]},{"cell_type":"markdown","id":"2c26771a-4bea-4888-b2b6-6d3544b1050c","metadata":{},"outputs":[],"source":["The default scoring is R^2. Each element in the array has the average R^2 value for the fold:\n"]},{"cell_type":"code","id":"aad32313-1338-4b84-b5c1-d30fceb4faad","metadata":{},"outputs":[],"source":["Rcross"]},{"cell_type":"markdown","id":"ac9cff95-9035-4507-84cc-513fcf562855","metadata":{},"outputs":[],"source":["We can calculate the average and standard deviation of our estimate:\n"]},{"cell_type":"code","id":"43510c99-a433-4e6b-8970-c9c94b7db5f6","metadata":{},"outputs":[],"source":["print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\", Rcross.std())"]},{"cell_type":"markdown","id":"4fcd184b-a83e-477f-a727-bc6dd72ca24e","metadata":{},"outputs":[],"source":["We can use negative squared error as a score by setting the parameter  'scoring' metric to 'neg_mean_squared_error'.\n"]},{"cell_type":"code","id":"ca9b2c43-8151-474d-aebf-567412a5d8df","metadata":{},"outputs":[],"source":["-1 * cross_val_score(lm, x_data[['Units Pkg']], y_data, cv=4, scoring='neg_mean_squared_error')"]},{"cell_type":"markdown","id":"08672d5b-a9c6-47b2-9460-c5dcd3d25afe","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #3:\u003c/b\u003e\n","    \n","\u003cb\u003eCalculate the average R^2 using two folds, then find the average R^2 for the second fold utilizing the \"Sales Pkg\" feature:\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"2c491b35-c599-4ce6-a1f6-e74af115763e","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"f3437999-817c-4f9a-834c-165ef11d0cd5","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","Rcross_ex = cross_val_score(lm, x_data[[\"Units Pkg\"]], y_data, cv=2)\n","Rcross_ex.mean()\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"60de65ac-b732-4300-83d7-de9e637040e1","metadata":{},"outputs":[],"source":["You can also use the function \u003ccode\u003ecross_val_predict\u003c/code\u003e to predict the output. The function splits up the data into the specified number of folds, with one fold for testing and the other folds are used for training.\n"]},{"cell_type":"markdown","id":"a26b6544-33d6-498e-937a-647659d16115","metadata":{},"outputs":[],"source":["We input the object, the feature \u003cb\u003e\"Units Pkg\"\u003c/b\u003e, and the target data \u003cb\u003ey_data\u003c/b\u003e. The parameter 'cv' determines the number of folds. In this case, it is 4. We can produce an output:\n"]},{"cell_type":"code","id":"7fa4ecc2-d9fc-4aca-aa60-43e221a4edec","metadata":{},"outputs":[],"source":["yhat = cross_val_predict(lm, x_data[['Units Pkg']], y_data, cv=4)\nyhat"]},{"cell_type":"markdown","id":"4512c34f-9fb0-4b1b-b96c-440eabb1b4af","metadata":{},"outputs":[],"source":["Let's see how good our model is:\n"]},{"cell_type":"code","id":"a3ef2529-f057-4ce3-abe7-f290d5e02317","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n\nplt.title(\"Predicted vs real value\")\nplt.xlabel(\"Index of Units Pkg (X) from 0 to 4137\")\nplt.ylabel(\"Turnover (Y)\")\n\ny_data.plot()\nplt.plot(y_data.index, yhat)"]},{"cell_type":"markdown","id":"0151ce21-d17c-42b4-887e-ac133a272148","metadata":{},"outputs":[],"source":["We see that out model fits very poorly. \n"]},{"cell_type":"markdown","id":"73f0f7ed-cddc-4db8-81ba-56e2711dc796","metadata":{},"outputs":[],"source":["\u003cdiv style=\"margin-top: 1em;\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold; text-decoration: none;\"\u003e\u003ca name=\"ref2\"\u003e\u003cfont color=\"black\"\u003ePart 2: Overfitting, Underfitting and Model Selection\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\u003c/div\u003e\n","\n","We've seen an example of underfitting in previous chapter ('lm' model) - an example of poor learn.\n","\u003cp\u003eIt turns out that the test data, sometimes referred to as the \"out of sample data\", is a much better measure of how well your model performs in the real world.  One reason for this is overfitting.\n","\n","Let's go over some examples. It turns out these differences are more apparent in Multiple Linear Regression and Polynomial Regression so we will explore overfitting in that context.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"e27e69bf-5b02-4ba6-b9c0-97fc461d48eb","metadata":{},"outputs":[],"source":["#### **Underfitting**\n"]},{"cell_type":"markdown","id":"416475ea-1634-45af-a67d-13468a5217bd","metadata":{},"outputs":[],"source":["Let's create \u003cb\u003eMultiple Linear Regression\u003c/b\u003e objects and train the model using 'Sales Pkg', 'Units Pkg', 'Avg Price Pkg' as features.\n"]},{"cell_type":"code","id":"ee307d8c-0fa6-423c-8c3c-cf6dfbb3f312","metadata":{},"outputs":[],"source":["lm1 = LinearRegression()\nlm1.fit(x_train[['Units Pkg', 'Avg Price Pkg', 'Group']], y_train)"]},{"cell_type":"markdown","id":"6ceb7110-ef12-4aad-88c4-44af6c411540","metadata":{},"outputs":[],"source":["Prediction using training data:\n"]},{"cell_type":"code","id":"e78bf6ae-e417-4d2c-add5-842e1ce39e0e","metadata":{},"outputs":[],"source":["yhat_train = lm1.predict(x_train[['Units Pkg', 'Avg Price Pkg', 'Group']])\nyhat_train[0:5]"]},{"cell_type":"markdown","id":"9f8fc28e-6224-4d57-a301-8dece90e6d1a","metadata":{},"outputs":[],"source":["Prediction using test data:\n"]},{"cell_type":"code","id":"fa4a6c71-4402-4683-8a0f-2826f2bed2d0","metadata":{},"outputs":[],"source":["yhat_test = lm1.predict(x_test[['Units Pkg', 'Avg Price Pkg', 'Group']])\nyhat_test[0:5]"]},{"cell_type":"markdown","id":"5719847d-d003-4b0a-90ac-6a9f467db101","metadata":{},"outputs":[],"source":["Calculate r-scores:\n"]},{"cell_type":"code","id":"b17ac2f9-7fbb-419f-a5f6-c9d83197b352","metadata":{},"outputs":[],"source":["lm1.score(x_train[['Units Pkg', 'Avg Price Pkg', 'Group']], y_train)"]},{"cell_type":"code","id":"9f31399d-1961-4887-8f65-697bae653950","metadata":{},"outputs":[],"source":["lm1.score(x_test[['Units Pkg', 'Avg Price Pkg', 'Group']], y_test)"]},{"cell_type":"markdown","id":"669d2d34-4f2a-4bb4-8d89-1d97e2ae9f52","metadata":{},"outputs":[],"source":["Very low r-score is a sign of underfitting.\n"]},{"cell_type":"markdown","id":"7d7f86d4-28f2-482e-a1ef-124bf2673f05","metadata":{},"outputs":[],"source":["Let's perform some model evaluation using our training and testing data separately.\n"]},{"cell_type":"markdown","id":"766cda12-54d2-4c8c-b99a-3e3ad7b07754","metadata":{},"outputs":[],"source":["Let's examine the distribution of the predicted values of the training data.\n"]},{"cell_type":"code","id":"2c7615ab-fb7b-4241-bb57-4e53579aa02e","metadata":{},"outputs":[],"source":["Title = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title) # red color - actual data, blue - predicted"]},{"cell_type":"markdown","id":"a77e3736-b768-4bad-b54e-3c388f684c83","metadata":{},"outputs":[],"source":["\u003cb\u003eFigure 1\u003c/b\u003e: Plot of predicted values using the training data compared to the actual values of the training data.\n"]},{"cell_type":"markdown","id":"b089c29e-8a68-4069-ba3c-6f93f7e25600","metadata":{},"outputs":[],"source":["The model seems to be doing badly in learning from the training dataset. We already might guess that on testing data model will do this badly as well. Let's check:\n"]},{"cell_type":"code","id":"e663ac9b-7f6e-4b8c-8407-8a6770d342ad","metadata":{},"outputs":[],"source":["Title = 'Distribution Plot of Predicted Value Using Test Data vs Data Distribution of Test Data'\nDistributionPlot(y_test, yhat_test, \"Actual Values (Test)\", \"Predicted Values (Test)\", Title)"]},{"cell_type":"markdown","id":"db630d6e-aa68-4ef6-b483-3abaa43016a7","metadata":{},"outputs":[],"source":["\u003cb\u003eFigure 2\u003c/b\u003e: Plot of predicted value using the test data compared to the actual values of the test data.\n"]},{"cell_type":"markdown","id":"4e967af5-bf2c-4f0d-b522-ba0c920ad5a7","metadata":{},"outputs":[],"source":["\u003cp\u003eComparing Figure 1 and Figure 2, we can see that the distribution of the train data in Figure 1 and the distribution of the test data in Figure 2 are almost equally bad at fitting the data. Let's see if polynomial regression is a better choice than linear one in the prediction accuracy when analysing the test dataset.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"4653046e-fe63-4ba2-8664-20db34496c39","metadata":{},"outputs":[],"source":["#### **Overfitting**\n","Overfitting is a problem that occurs when a model is too complex and when the model fits the noise, but not the underlying process. This results in a model that is highly accurate on the training data but performs poorly on new data that it has not seen before. Essentially, the model becomes too tailored to the training data and is unable to generalize to new data. Overfitting can occur when a model is too complex or when there is not enough data to train the model properly.\n","\u003cp\u003eTherefore, when testing your model using the test set, your model does not perform as well since it is modelling noise, not the underlying process that generated the relationship. Let's create a degree 5 polynomial model.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"06c8dbdb-1404-400d-ac02-34e8cb73ad18","metadata":{},"outputs":[],"source":["Let's use 45 percent of the data for training and the rest for testing: (to achieve overfitting model example)\n"]},{"cell_type":"code","id":"6b8eec8b-52c2-43e8-a82f-dc0809f4106a","metadata":{},"outputs":[],"source":["x_train_poly, x_test_poly, y_train_poly, y_test_poly = train_test_split(x_data, y_data, test_size=0.55, random_state=0)"]},{"cell_type":"markdown","id":"16e069fa-a34e-4321-8764-9eb229fe5014","metadata":{},"outputs":[],"source":["We will perform a degree 7 polynomial transformation on the feature \u003cb\u003e'Sales Pkg' (we use only for example of overfitting)\u003c/b\u003e.\n"]},{"cell_type":"code","id":"929e5525-05f9-4084-897c-c80886c5c66d","metadata":{},"outputs":[],"source":["pr = PolynomialFeatures(degree=7)\nx_train_pr = pr.fit_transform(x_train_poly[['Sales Pkg']])\nx_test_pr = pr.fit_transform(x_test_poly[['Sales Pkg']])\npr"]},{"cell_type":"markdown","id":"42252fb1-3c7b-41c7-bd2d-7985a2da1334","metadata":{},"outputs":[],"source":["Now, let's create a Linear Regression model \"poly\" and train it.\n"]},{"cell_type":"code","id":"ca2531b4-81d9-46f3-9d88-68a65b61fbef","metadata":{},"outputs":[],"source":["poly = LinearRegression()\npoly.fit(x_train_pr, y_train_poly)"]},{"cell_type":"markdown","id":"f354fe9c-2994-4fbc-b80c-ca5cc8189522","metadata":{},"outputs":[],"source":["We can see the output of our model using the method \u003ccode\u003epredict\u003c/code\u003e We assign the values to \"yhat\".\n"]},{"cell_type":"code","id":"aa006e03-8923-45c1-9be1-55c107771393","metadata":{},"outputs":[],"source":["yhat_poly = poly.predict(x_test_pr)\nyhat_poly[0:5]"]},{"cell_type":"markdown","id":"f5dfe3e9-c761-48a7-a181-c05314ca6c91","metadata":{},"outputs":[],"source":["Let's take the first five predicted values and compare it to the actual targets.\n"]},{"cell_type":"code","id":"cbb8905d-2dff-460e-9ca6-bc1c60746c52","metadata":{},"outputs":[],"source":["print(\"Predicted values:\", yhat_poly[0:4])\nprint(\"True values:\", y_test_poly[0:4].values)"]},{"cell_type":"markdown","id":"36d2e35c-4af2-4892-af22-52f32a48a53e","metadata":{},"outputs":[],"source":["We will use the function \"PollyPlot\" that we defined at the beginning of the lab to display the training data, testing data, and the predicted function.\n"]},{"cell_type":"code","id":"234e375c-0e37-47c9-941f-64fe05cc876f","metadata":{},"outputs":[],"source":["PollyPlot(x_train_poly[['Sales Pkg']], x_test_poly[['Sales Pkg']], y_train_poly, y_test_poly, poly, pr)"]},{"cell_type":"markdown","id":"e39e6dc6-8ae7-4012-a4c6-7460aa9f7c14","metadata":{},"outputs":[],"source":["Figure 3: A polynomial regression model where red dots represent training data, green dots represent test data, and the blue line represents the model prediction.\n"]},{"cell_type":"markdown","id":"717d124c-037a-444b-b92f-e8db372cb5f1","metadata":{},"outputs":[],"source":["We see that the test data and the train data are highly overlapped and they fit the predicted function well.\n"]},{"cell_type":"markdown","id":"549bf339-d021-4c74-8cde-b78aa85df9a9","metadata":{},"outputs":[],"source":["R^2 of the training data:\n"]},{"cell_type":"code","id":"ca3b1ee1-edf5-480c-9cd0-9ea8e1026dbf","metadata":{},"outputs":[],"source":["poly.score(x_train_pr, y_train_poly)"]},{"cell_type":"markdown","id":"39d38cf2-7eef-4cb4-91f1-a98be407a757","metadata":{},"outputs":[],"source":["R^2 of the test data:\n"]},{"cell_type":"code","id":"5694dd55-6f77-4efc-b092-be33cd5c5da3","metadata":{},"outputs":[],"source":["poly.score(x_test_pr, y_test_poly)"]},{"cell_type":"markdown","id":"94db0d69-b241-4257-99fa-16236c55ec26","metadata":{},"outputs":[],"source":["We see the R^2 for the training data is 0.89 while the R^2 on the test data is -1.77. The lower the R^2, the worse the model. \u003cb\u003eIf r-scores for test and train data are quite different and train r-score are quite high is a sign of overfitting.\u003c/b\u003e In our case, it's a very clear sign of overfitting: model (poly) learnt great on training data, but cannot predict on test data.\n"]},{"cell_type":"markdown","id":"4db87121-e19c-4fe4-a359-2b065cac7c29","metadata":{},"outputs":[],"source":["Let's see how the R^2 changes on the \u003cb\u003etest\u003c/b\u003e data for different order polynomials and then plot the results:\n"]},{"cell_type":"code","id":"52f2906d-95e8-4e59-b984-fb53d09e090f","metadata":{},"outputs":[],"source":["Rsqu_test = []\n\norder = [1, 2, 3, 4, 5, 6, 7]\nfor n in order:\n    pr = PolynomialFeatures(degree=n)\n    \n    x_train_pr = pr.fit_transform(x_train_poly[['Sales Pkg']])\n    \n    x_test_pr = pr.fit_transform(x_test_poly[['Sales Pkg']])    \n    \n    lm1.fit(x_train_pr, y_train_poly)\n    \n    Rsqu_test.append(lm1.score(x_test_pr, y_test_poly))\n    \n# plt.figure(figsize=(3, 2))\nplt.plot(order, Rsqu_test)\nplt.xlabel('order')\nplt.ylabel('R^2')\nplt.title('R^2 Using Test Data')\nplt.text(6, 0.95, 'Max R^2')  "]},{"cell_type":"markdown","id":"8e283d32-d218-4d1b-b741-36db57b7dd2f","metadata":{},"outputs":[],"source":["We see the R^2 gradually increases until an order 6 polynomial is used. Then, the R^2 dramatically decreases at an order 7th polynomial.\n"]},{"cell_type":"markdown","id":"01ca3db0-7c03-4b86-8b06-8d97cd98301f","metadata":{},"outputs":[],"source":["The following function will be used in the next section. Please run the cell below.\n"]},{"cell_type":"code","id":"a8ae9f72-9784-4d7d-90ab-71a1fc59494a","metadata":{},"outputs":[],"source":["def f(order, test_data):\n    x_train_sample, x_test_sample, y_train_sample, y_test_sample = train_test_split(x_data, y_data, test_size=test_data, random_state=0)\n    # Create polynomial features for training and test sets\n    pr_sample = PolynomialFeatures(degree=order)\n    X_train_poly_sample = pr_sample.fit_transform(x_train_sample[['Sales Pkg']])\n    X_test_poly_sample = pr_sample.fit_transform(x_test_sample[['Sales Pkg']])\n\n    # Fit linear regression model to training data\n    lin_reg = LinearRegression()\n    lin_reg.fit(X_train_poly_sample, y_train_sample)\n\n    # Predict on test data and calculate R^2 score\n    y_pred = lin_reg.predict(X_test_poly_sample)\n    r2_score = lin_reg.score(X_test_poly_sample, y_test_sample)\n\n    # Plot the test data and polynomial fit\n    PollyPlot(x_train_sample[['Sales Pkg']], x_test_sample[['Sales Pkg']], y_train_sample, y_test_sample, lin_reg, pr_sample)\n    plt.show()"]},{"cell_type":"markdown","id":"05fb7821-978f-4fe6-8911-d029f1bb293d","metadata":{},"outputs":[],"source":["The following interface allows you to experiment with different polynomial orders and different amounts of data.\n"]},{"cell_type":"code","id":"0b184f15-4a3d-46f9-a272-5b3bbdd45311","metadata":{},"outputs":[],"source":["interact(f, order=(0, 10, 1), test_data=(0.05, 0.95, 0.05))"]},{"cell_type":"markdown","id":"74cf118f-2978-4cc5-b134-43c290f03da2","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4 a):\u003c/b\u003e\n","\n","\u003cb\u003eWe can perform polynomial transformations with more than one feature. Create a \"PolynomialFeatures\" object \"pr1\" of degree two.\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"5f7605da-ceaf-4a90-afd5-4f98c809d819","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"54dc549b-2b05-4553-9c55-3f368b2fde0a","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","pr1 = PolynomialFeatures(degree=2)\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"3e9f41d1-d137-4b07-8b18-0ca58abbfd97","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4 b):\u003c/b\u003e\n","    \n","\u003cb\u003eTransform the training and testing samples for the features 'Date', 'Units Pkg', 'Avg Price Pkg'. Hint: use the method \"fit_transform\".\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"9159e692-b1ca-41e6-8fa6-bc8ad7a125d3","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"a8e633c8-e6a1-42f4-9f1f-04e08bb0abc9","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n","\n","x_train1_pr = pr1.fit_transform(x_train1[['Date', 'Units Pkg', 'Avg Price Pkg']])\n","x_test1_pr = pr1.fit_transform(x_test1[['Date', 'Units Pkg', 'Avg Price Pkg']])\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"b6479e9c-81c0-4be7-a2f5-60673439a1a9","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4 c):\u003c/b\u003e\n","    \n","\u003cb\u003eHow many dimensions does the new feature have? Hint: use the attribute \"shape\".\n","\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"5f89719b-5ad9-4adb-b5bf-ad304a2575bf","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"5dfae7d5-2a37-4f1f-a979-324cef6b0bcb","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","x_train1_pr.shape #10 features\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"abab1c16-8c2a-402e-8b02-51c88614fd85","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4 d):\u003c/b\u003e\n","    \n","\u003cb\u003eCreate a linear regression model \"poly1\". Train the object using the polynomial features.\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"cfc15312-f612-4534-9ab5-f93cf43f1067","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"d39f8e90-9eb9-4f63-8727-a9d71e757843","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","poly1 = LinearRegression()\n","poly1.fit(x_train1_pr, y_train1)\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"62882098-4f50-44d5-b3c6-d9e95ddfb141","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #4 e):\u003c/b\u003e\n","    \n","\u003cb\u003ePredict an output on the polynomial features, then use the function \"DistributionPlot\" to display the distribution of the predicted test output vs. the actual test data.\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"8a0f9b8b-fb8d-4c65-aff9-bfe8fe3e172e","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"eccaa180-a274-4769-95f4-002fda7979b4","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","y_hat_poly1 = poly1.predict(x_test1_pr)\n","\n","Title = 'Distribution Plot of Predicted Value Using Test Data vs Data Distribution of Test Data'\n","DistributionPlot(y_test1, y_hat_poly1, \"Actual Values (Test)\", \"Predicted Values (Test)\", Title) \n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"c2ef667b-0587-41e1-9406-037be75863f3","metadata":{},"outputs":[],"source":["\u003cdiv style=\"margin-top: 1em;\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold; text-decoration: none;\"\u003e\u003ca name=\"ref3\"\u003e\u003cfont color=\"black\"\u003ePart 3: Ridge Regression\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"0e9bda80-87ec-4530-8a4d-94b58ef47cb4","metadata":{},"outputs":[],"source":["In this section, we will review Ridge Regression and see how the parameter \u003cb\u003ealpha\u003c/b\u003e changes the model. Just a note, here our test data will be used as validation data.\n"]},{"cell_type":"markdown","id":"bfaf9614-30fe-4ccc-9832-0e787063fecf","metadata":{},"outputs":[],"source":["Ridge regression is a linear regression method used for dealing with multicollinearity (high correlation between independent variables) in data. It adds a penalty term to the cost function of linear regression, which is the sum of squared differences between the predicted values and actual values. \n"]},{"cell_type":"markdown","id":"3e99a130-0ca3-4b29-886b-a4e7b059410d","metadata":{},"outputs":[],"source":["Let's perform a degree two polynomial transformation on our data.\n"]},{"cell_type":"code","id":"47bed5f3-63ba-45d4-8331-7479cf362257","metadata":{},"outputs":[],"source":["pr2 = PolynomialFeatures(degree=2)\nx_train2_pr = pr2.fit_transform(x_train[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']])\nx_test2_pr = pr2.fit_transform(x_test[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']])"]},{"cell_type":"markdown","id":"56d40502-910a-410d-8f80-9dceb9707519","metadata":{},"outputs":[],"source":["Let's import  \u003cb\u003eRidge\u003c/b\u003e  from the module \u003cb\u003elinear models\u003c/b\u003e.\n"]},{"cell_type":"code","id":"a728918f-4efe-46a9-a9da-be4630bd9953","metadata":{},"outputs":[],"source":["from sklearn.linear_model import Ridge"]},{"cell_type":"markdown","id":"bb3b8199-ed5f-45c9-b3aa-f8888437999b","metadata":{},"outputs":[],"source":["Let's create a Ridge regression object, setting the regularization parameter (alpha) to 0.1\n"]},{"cell_type":"code","id":"828c8158-e515-47ae-978f-bd4a66f16308","metadata":{},"outputs":[],"source":["RidgeModel = Ridge(alpha=1) "]},{"cell_type":"markdown","id":"57a76a83-75dc-410b-bf82-319a6dce3452","metadata":{},"outputs":[],"source":["Like regular regression, you can fit the model using the method \u003cb\u003efit\u003c/b\u003e.\n"]},{"cell_type":"code","id":"a896cd0e-388d-4e76-8793-54aa43b0fe66","metadata":{},"outputs":[],"source":["RidgeModel.fit(x_train2_pr, y_train)"]},{"cell_type":"markdown","id":"7f65ee78-9736-46dc-adaf-7ef2a5ca2629","metadata":{},"outputs":[],"source":["Similarly, you can obtain a prediction:\n"]},{"cell_type":"code","id":"6b3b5193-37fb-4ad1-a21b-76ddc1b211e6","metadata":{},"outputs":[],"source":["y_hat_poly2 = RidgeModel.predict(x_test2_pr)"]},{"cell_type":"markdown","id":"7e0b7a37-7f94-4501-8c01-241ccad0a0c1","metadata":{},"outputs":[],"source":["Let's compare the first five predicted samples to our test set:\n"]},{"cell_type":"code","id":"861c3340-9348-4128-b006-8756b285d148","metadata":{},"outputs":[],"source":["print('predicted:', y_hat_poly2[0:4])\nprint('test set :', y_test[0:4].values)"]},{"cell_type":"markdown","id":"331fed83-4bbc-4375-89f7-5e1999121e2c","metadata":{},"outputs":[],"source":["Let's visualize:\n"]},{"cell_type":"code","id":"683d9ec5-2516-49e6-9fb3-144859ee1556","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n\nres = pd.DataFrame(y_test)\nres['Yhat'] = y_hat_poly2\nres.sort_index().plot()\n\nplt.title(\"Predicted data using testing data vs real value using testing data\")\nplt.xlabel(\"x_test2_pr\")\nplt.ylabel(\"Turnover (Y)\")"]},{"cell_type":"markdown","id":"5ec1e34b-fe2a-4d37-9d9c-edb5b34dd921","metadata":{},"outputs":[],"source":["We select the value of alpha that minimizes the test error. To do so, we can use a for loop. We have also created a progress bar to see how many iterations we have completed so far.\n"]},{"cell_type":"code","id":"98aafc3a-677d-449e-88d2-5c443cb6c738","metadata":{},"outputs":[],"source":["from tqdm import tqdm\n\nRsqu_test1 = []\nRsqu_train1 = []\ndummy1 = []\nAlpha = 10 * np.array(range(0,1000))\npbar = tqdm(Alpha)\n\nfor alpha in pbar:\n    RidgeModel = Ridge(alpha=alpha) \n    RidgeModel.fit(x_train2_pr, y_train)\n    test_score, train_score = RidgeModel.score(x_test2_pr, y_test), RidgeModel.score(x_train2_pr, y_train)\n    \n    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n\n    Rsqu_test1.append(test_score)\n    Rsqu_train1.append(train_score)"]},{"cell_type":"markdown","id":"14759ad6-2403-45a2-9af3-85bc2aae77b0","metadata":{},"outputs":[],"source":["We can plot out the value of R^2 for different alphas:\n"]},{"cell_type":"code","id":"31ce8a3d-c0db-4b7c-b0b3-e753cff6f412","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n\nplt.plot(Alpha, Rsqu_test1, label='validation (test) data  ')\nplt.plot(Alpha, Rsqu_train1, 'r', label='training data ')\nplt.xlabel('alpha')\nplt.ylabel('R^2')\nplt.legend()"]},{"cell_type":"markdown","id":"df5552d4-63e2-4adb-b384-79ce7ba1f2c7","metadata":{},"outputs":[],"source":["**Figure 4**: The blue line represents the R^2 of the validation data, and the red line represents the R^2 of the training data. The x-axis represents the different values of Alpha. \n"]},{"cell_type":"markdown","id":"304b6b34-e6c8-4aae-bf25-9c3934d573ee","metadata":{},"outputs":[],"source":["As alpha increases the both R^2 decrease. Therefore, as alpha increases, the both models perform worse on the training data.\n"]},{"cell_type":"markdown","id":"7323c33c-542f-464c-9be5-4f45e618a437","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: bold;\"\u003eQuestion #5):\u003c/b\u003e\n","\n","\u003cb\u003ePerform Ridge regression. Calculate the R^2 using the polynomial features, use the training data to train the model and use the test data to test the model. The parameter alpha should be set to 10.\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"8b92c487-7c8b-4d62-85cf-d0aae6e835a4","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"77ed5e2b-f424-4975-a1a5-134b78873a6d","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","RidgeModel1 = Ridge(alpha=10) \n","RidgeModel1.fit(x_train2_pr, y_train)\n","RidgeModel1.score(x_test2_pr, y_test)\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"97f0dc08-71e9-402e-8eda-15fbb56a8b37","metadata":{},"outputs":[],"source":["\u003cdiv style=\"margin-top: 1em;\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold; text-decoration: none;\"\u003e\u003ca name=\"ref4\"\u003e\u003cfont color=\"black\"\u003ePart 4: Grid Search\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"aaa0d4da-8009-4fe6-814a-8d2333291458","metadata":{},"outputs":[],"source":["The term alpha is a hyperparameter. Sklearn has the class \u003cb\u003eGridSearchCV\u003c/b\u003e to make the process of finding the best hyperparameter simpler.\n"]},{"cell_type":"markdown","id":"714fdaf0-98de-41cf-9f1b-44147e913a59","metadata":{},"outputs":[],"source":["Let's import \u003cb\u003eGridSearchCV\u003c/b\u003e from  the module \u003cb\u003emodel_selection\u003c/b\u003e.\n"]},{"cell_type":"code","id":"b31078fe-7880-4298-bfe1-5e84f85e27cc","metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","id":"b8e10552-bf9b-4a72-9656-b621a7a85ce3","metadata":{},"outputs":[],"source":["We create a dictionary of possible parameter alpha values:\n"]},{"cell_type":"code","id":"f60015bd-56e1-40ac-9f78-bb2984e6b159","metadata":{},"outputs":[],"source":["parameters1 = [{'alpha': [0.001, 0.1, 1, 10, 100, 1000, 10000, 100000, 100000]}]\nparameters1"]},{"cell_type":"markdown","id":"48ae2d52-4e27-4798-b259-333bb4bcebda","metadata":{},"outputs":[],"source":["Create a Ridge regression object:\n"]},{"cell_type":"code","id":"8cb853b6-cf9f-451b-b05c-bf9a9253c70d","metadata":{},"outputs":[],"source":["RR = Ridge()\nRR"]},{"cell_type":"markdown","id":"8dacddfe-1c1a-4137-9a89-ee7f5b3a4352","metadata":{},"outputs":[],"source":["Create a ridge grid search object:\n"]},{"cell_type":"code","id":"fcf1936c-978d-409a-95df-19ba1518f5d8","metadata":{},"outputs":[],"source":["Grid1 = GridSearchCV(RR, parameters1, cv=4)"]},{"cell_type":"markdown","id":"d8e8166a-bc99-4d34-aedc-7626b968b3fe","metadata":{},"outputs":[],"source":["\n","Fit the model:\n"]},{"cell_type":"code","id":"f6ca760e-3b6f-47ce-a59d-ab93ae8dd0e3","metadata":{},"outputs":[],"source":["Grid1.fit(x_train[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']], y_train)"]},{"cell_type":"markdown","id":"b59cb978-17aa-4a56-b8ff-e64dc71da828","metadata":{},"outputs":[],"source":["The object finds the best parameter values on the validation data. We can obtain the estimator with the best parameters and assign it to the variable BestRR as follows:\n"]},{"cell_type":"code","id":"b1a558d0-fa98-4e66-954d-8ee0ef2643fe","metadata":{},"outputs":[],"source":["BestRR = Grid1.best_estimator_\nBestRR"]},{"cell_type":"code","id":"066723c6-0623-45c2-964d-3024c2e17649","metadata":{},"outputs":[],"source":["BestRR.score(x_test[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']], y_test)"]},{"cell_type":"markdown","id":"ce554e17-598a-4f3f-8ccd-dbf8153af3ec","metadata":{},"outputs":[],"source":["The best alpha is equal to 100.\n"]},{"cell_type":"code","id":"6b144c23-b273-4f74-ab13-331fd883653b","metadata":{},"outputs":[],"source":["RR = Ridge(alpha=100) \nRR.fit(x_train[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']], y_train)"]},{"cell_type":"markdown","id":"011ba6ce-95a0-41e7-bfac-25441ce4b5ce","metadata":{},"outputs":[],"source":["We now test our model on the test data:\n"]},{"cell_type":"code","id":"3bebc387-184a-4d0d-a585-2a549c7714f0","metadata":{},"outputs":[],"source":["y_grid_hat = RR.predict(x_test[['Units Pkg', 'Avg Price Pkg', 'Group', 'Date']])\n\nprint('predicted:', y_grid_hat[0:4])\nprint('test set :', y_test[0:4].values)"]},{"cell_type":"markdown","id":"d1d24678-07b7-4bae-b6aa-9ab507b386fe","metadata":{},"outputs":[],"source":["Visualize predicted using test data vs real test data:\n"]},{"cell_type":"code","id":"d0570bce-916b-478d-97db-0a5b3cb71dd8","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\nres = pd.DataFrame(y_test)\nres['Yhat'] = y_grid_hat\nres.sort_index().plot()\n\nplt.title(\"Predicted data using testing data vs real value using testing data\")\nplt.xlabel(\"x_test\")\nplt.ylabel(\"Turnover (Y)\")"]},{"cell_type":"markdown","id":"5e1855aa-92c7-4073-a493-4e46ad59ff11","metadata":{},"outputs":[],"source":["Unfortunately, model (RR) fits poorly. \n"]},{"cell_type":"markdown","id":"14e5b609-2386-49f4-a2d2-d907e0d0a29f","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","## Authors\n","\u003ca href=\"https://author.skills.network/instructors/rosana_klym?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX044EN3173-2023-01-01\"\u003eRosana Klym\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX044EN3173-2023-01-01\"\u003eYaroslav Vyklyuk\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/olga_kavun?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX044EN3173-2023-01-01\"\u003eOlga Kavun\u003c/a\u003e\n","\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                  |\n","| ----------------- | ------- | ---------- | ----------------------------------- |\n","| 2023-05-03       | 2.0     | Rosana     | Finished                                                         |\n","| 2023-05-03       | 2.1     | Rosana     | Changed URL                                                      |\n","| 2023-05-06       | 2.2     | Rosana     | Changed title styles, added anchor links and added plot RR model |\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e  IBM Corporation 2023. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}