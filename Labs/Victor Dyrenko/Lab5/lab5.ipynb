{"cells":[{"cell_type":"markdown","id":"399f3a56-76bf-4902-a8ce-7e418dead3a4","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","# Motorcycle sales analysis\n","\n","# *Lab5. Model Evaluation and Refinement*\n","\n","Estimated time needed: **1 hour**\n","\n","## Objectives\n","\n","After completing this lab you will be able to:\n","\n","*   Evaluate and refine prediction models\n"]},{"cell_type":"markdown","id":"d77114c0-2468-4881-aff8-30d4953ef764","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003e\u003cb style=\"font-size: 1.5em; font-weight: bold;\"\u003eClick here to see content, description of dataset, source of dataset and licence\u003c/b\u003e\u003c/summary\u003e\n","\u003cbr/\u003e\n","    \u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eContent\u003c/b\u003e\n","\u003cp\u003eYou work in the accounting department of a company that sells motorcycle parts. The company operates three warehouses in a large metropolitan area.\u003c/p\u003e\n","\n","\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eDataset Glossary (Column-wise)\u003c/b\u003e\n","\u003cul\u003e\n","    \u003cli\u003eDate\u003cp\u003eDetermines the date when client bought products\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eWarehouse\u003cp\u003eThe warehouse location.\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eClient type\u003cp\u003eDetermines how client bought the products. This column can be only Retail or Wholesale\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eProduct line\u003cp\u003eName of product (part of motorcycle)\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eQuantity\u003cp\u003eThe count bought product\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eUnit price\u003cp\u003eCost of one product\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003eTotal\u003cp\u003eThe total purchase price\u003c/p\u003e\u003c/li\u003e\n","    \u003cli\u003ePayment\u003cp\u003eDetermines the method of payment for the purchase. This dataset has three types of payment: Credit card, cash or transfer\u003c/p\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eTarget field\u003c/b\u003e\n","\u003cul\u003e\n","    \u003cli\u003eTotal\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eData source and licence\u003c/b\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003eData source: \u003ca href=\"https://www.kaggle.com/datasets/devijeganath/motorcycle-sales-analysis?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0TE4EN3049-2023-01-01\"\u003ehttps://www.kaggle.com/datasets/devijeganath/motorcycle-sales-analysis\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003eData type: csv\u003c/li\u003e\n","    \u003cli\u003eLicence: \u003ca href=\"https://creativecommons.org/publicdomain/zero/1.0/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0TE4EN3049-2023-01-01\"\u003eCC0: Public Domain\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003e\n","This DataSet released under CC0: Public Domain license that allow of copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission.\n","The person who associated a work with this deed has dedicated the work to the public domain by waiving all of his or her rights to the work worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law.\n","\u003c/p\u003e\n","You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission.\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"1cf775e9-8d0b-4eb3-8c58-437ab6875d4a","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.5em; font-weight: bold;\"\u003eTable of Contents\u003c/b\u003e\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003col\u003e\n","    \u003cli\u003e\u003ca href=\"#id1\"\u003eTraining and testing\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#id2\"\u003eUnderfitting and Model Selection\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#id3\"\u003eRidge Regression\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#id4\"\u003eGrid Search\u003c/a\u003e\u003c/li\u003e\n","\u003c/ol\u003e\n","\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"025132c3-f19b-4f91-bcd7-93bc90f20137","metadata":{},"outputs":[],"source":["Import libraries\n"]},{"cell_type":"code","id":"bd76d9d1-d4db-4cd9-8db6-753f6b7ee8cb","metadata":{},"outputs":[],"source":["#install specific version of libraries used in lab\n#! mamba install pandas -y\n#! mamba install numpy -y\n#! mamba install sklearn -y\n#! mamba install   ipywidgets -y\n#! mamba install tqdm\n\n! mamba install scikit-learn -y"]},{"cell_type":"code","id":"0e600853-c63e-42d0-abd2-d84dfab04425","metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import OrdinalEncoder, PolynomialFeatures\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.model_selection import cross_val_score, train_test_split, cross_val_predict, GridSearchCV\nfrom tqdm import tqdm\nfrom sklearn import set_config\nset_config(display=\"diagram\")\nwarnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"29c35974-2aca-4bf3-8cbd-63ae89a9f462","metadata":{},"outputs":[],"source":["This dataset was hosted on IBM Cloud object. Click \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0TE4EN/new_motorcycles.csv\"\u003eHERE\u003c/a\u003e for free storage.\n"]},{"cell_type":"code","id":"bd6a3857-9533-4538-9a76-e89d44b83c36","metadata":{},"outputs":[],"source":["path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0TE4EN/new_motorcycles.csv'"]},{"cell_type":"code","id":"af7c487b-10d1-4be2-a143-16f39b3e0f44","metadata":{},"outputs":[],"source":["df = pd.read_csv(path)\ndf.head()"]},{"cell_type":"markdown","id":"d6a62f5f-b29d-4802-8430-987ac93814ea","metadata":{},"outputs":[],"source":["\u003cp\u003eFirst, we need to use \u003ccode\u003eOrdinalEncoder\u003c/code\u003e to transform all our not numeric values in the numbers\u003c/p\u003e\n"]},{"cell_type":"code","id":"b93f8929-ae30-437b-89c6-d2ccd2d00e9e","metadata":{},"outputs":[],"source":["enc = OrdinalEncoder()\ndf[['Product line','Quantity binned','Total ranged']] = enc.fit_transform(df[['Product line','Quantity binned','Total ranged']])"]},{"cell_type":"code","id":"a1239e38-a0a3-4f1c-b1f0-09388337aed7","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","id":"9c335d5b-210a-4c41-8f0e-85e389a9270c","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eFunctions for Plotting\u003c/b\u003e\n"]},{"cell_type":"code","id":"e749f1d7-8b3e-4b3b-a966-1a6c39fb466c","metadata":{},"outputs":[],"source":["def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 12\n    height = 10\n    plt.figure(figsize = (width, height))\n\n    ax1 = sns.distplot(RedFunction, hist = False, color = \"r\", label = RedName)\n    sns.distplot(BlueFunction, hist = False, color = \"b\", label = BlueName, ax = ax1)\n\n    plt.title(Title)\n    plt.xlabel('Total')\n    plt.ylabel('Proportion of predictors')\n\n    plt.show()\n    plt.close()"]},{"cell_type":"code","id":"6a69b08e-20da-473e-bacd-7fb270f5f842","metadata":{},"outputs":[],"source":["def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n    width = 12\n    height = 10\n    plt.figure(figsize=(width, height))\n    \n    \n    #training data \n    #testing data \n    # lr:  linear regression object \n    #poly_transform:  polynomial transformation object \n \n    xmax = max([xtrain.values.max(), xtest.values.max()])\n\n    xmin = min([xtrain.values.min(), xtest.values.min()])\n\n    x = np.arange(xmin, xmax, 0.1)\n\n\n    plt.plot(xtrain, y_train, 'ro', label = 'Training Data')\n    plt.plot(xtest, y_test, 'go', label = 'Test Data')\n    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label = 'Predicted Function')\n    plt.ylim([min(y_train), max(y_train)])\n    plt.ylabel('Total')\n    plt.legend()\n    plt.show()"]},{"cell_type":"markdown","id":"cc926cf9-49b8-43b9-9f48-af50c807e6b3","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.5em; font-weight: bold\"\u003e\u003ca name=\"id1\" style=\"text-decoration: none;\"\u003e\u003cfont color=\"black\"\u003e1. Training and Testing\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\n","\u003cp\u003eAn important step in testing your model is to split your data into training and testing data. We will place the target data \u003cb\u003eTotal\u003c/b\u003e in a separate dataframe \u003cb\u003ey_data\u003c/b\u003e:\u003c/p\u003e\n"]},{"cell_type":"code","id":"463662a3-f494-4304-b22e-100c18a248e1","metadata":{},"outputs":[],"source":["y_data = df['Total']"]},{"cell_type":"markdown","id":"3a5b3a9f-fb6e-440e-b98c-61a085ee208a","metadata":{},"outputs":[],"source":["Drop data from column Total in dataframe **x_data**:\n"]},{"cell_type":"code","id":"c10bfd1c-30f3-4921-be44-c623ed67ad72","metadata":{},"outputs":[],"source":["x_data = df.drop('Total',axis=1)"]},{"cell_type":"markdown","id":"cdda6dca-5564-4bbb-958d-16cb7bcfd244","metadata":{},"outputs":[],"source":["Now, we randomly split our data into training and testing data using the function \u003cb\u003etrain_test_split\u003c/b\u003e.\n"]},{"cell_type":"code","id":"c496cd7d-3c3f-401a-b6aa-c31905005454","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2, shuffle = False)\nprint(\"number of test samples :\", x_test.shape[0])\nprint(\"number of training samples:\",x_train.shape[0])"]},{"cell_type":"markdown","id":"67e21ecf-68e0-4c89-87d6-266f65e66581","metadata":{},"outputs":[],"source":["The \u003cb\u003etest_size\u003c/b\u003e parameter sets the proportion of data that is split into the testing set. In the above, the testing set is 20% of the total dataset.\n"]},{"cell_type":"markdown","id":"cf24984b-3c5d-4d6f-9923-5a8ed0b66d4e","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003e Question  #1:\u003c/b\u003e\n","\n","\u003cb style=\"font-size: 1.2em\"\u003eUse the function \"train_test_split\" to split up the dataset such that 30% of the data samples will be utilized for testing. The output of the function should be the following:  \"x_train1\" , \"x_test1\", \"y_train1\" and  \"y_test1\". Set the parameter \u003ccode\u003eshuffle = False\u003c/code\u003e\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"60d99dc2-ff3e-49a7-93f9-236fd4a13e54","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"33dbb709-f6fa-4bff-90f7-56d7110e82ba","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(x_data, y_data, test_size = 0.3, shuffle = False) \n","print(\"number of test samples :\", x_test1.shape[0])\n","print(\"number of training samples:\",x_train1.shape[0])\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"b62060a9-4a6c-4570-a453-250cf52dbfe2","metadata":{},"outputs":[],"source":["We create a Linear Regression object:\n"]},{"cell_type":"code","id":"cd5e1fda-afe2-4d8e-913d-86e9fcad7f18","metadata":{},"outputs":[],"source":["lre = LinearRegression()"]},{"cell_type":"markdown","id":"d61f0a18-eda1-43a3-b1d5-9d1c663c5569","metadata":{},"outputs":[],"source":["We fit the model using the feature \"Quantity\":\n"]},{"cell_type":"code","id":"769f318a-70b9-4f26-8f82-0541798bf2cb","metadata":{},"outputs":[],"source":["lre.fit(x_train[['Quantity']], y_train)"]},{"cell_type":"markdown","id":"2287f571-6713-4672-ba1b-3184d4b9e6f2","metadata":{},"outputs":[],"source":["\u003cb\u003eLet's calculate the $R^{2}$ on the test data:\u003c/b\u003e\n"]},{"cell_type":"code","id":"bb1ad334-8328-491c-82a3-f97da85d2a77","metadata":{},"outputs":[],"source":["lre.score(x_test[['Quantity']], y_test)"]},{"cell_type":"markdown","id":"53dd44fd-4066-48a1-91f9-8ca794ed7130","metadata":{},"outputs":[],"source":["Let's calculate the $R^{2}$ on the train data:\n"]},{"cell_type":"code","id":"4c239c73-b814-4690-8351-81e7c5a66368","metadata":{},"outputs":[],"source":["lre.score(x_train[['Quantity']], y_train)"]},{"cell_type":"markdown","id":"634c17a8-0e81-4e22-9c10-4660243f1218","metadata":{},"outputs":[],"source":["We can see the $R^{2}$ is almost equal between train data and test data\n"]},{"cell_type":"markdown","id":"13ea45db-0658-4a36-80bd-9e7a8d51bd22","metadata":{},"outputs":[],"source":["Now let's create model \u003ccode\u003elrem\u003c/code\u003e for multiple linear regression with all features except for 'Total' and find $R^{2}$ for test and train data\n"]},{"cell_type":"code","id":"914459b0-1336-4144-9654-cd78dc225589","metadata":{},"outputs":[],"source":["lrem = LinearRegression()\nlrem.fit(x_train, y_train)\nprint('R^2 for test data: ',lrem.score(x_test, y_test))\nprint('R^2 for train data: ',lrem.score(x_train, y_train))"]},{"cell_type":"markdown","id":"f7442bec-6a86-4ced-8123-3f0306effa45","metadata":{},"outputs":[],"source":["You see that in case of multiple regression $R^{2}$ for test and train data are almost equal and don't much different from $R^{2}$ score in case simple linear regression\n"]},{"cell_type":"markdown","id":"03e1f735-a0ea-4538-95b9-372ec63658ae","metadata":{},"outputs":[],"source":["You see that $R^{2}$ score for test data and train data is almost equal but this score isn't high, so it is a sign of underfitting. You can learn about underfitting in **2.**\n"]},{"cell_type":"markdown","id":"81297257-5287-49f5-8db6-5ec8241e68a3","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003e Question  #2: \u003c/b\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eCreate new Linear Regression object \u003ccode\u003elre1\u003c/code\u003e for simple linear regression\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eUse method \u003ccode\u003efit()\u003c/code\u003e to train your model with the feature Quantity\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eFind the $R^{2}$ on the test data and train data using 30% of the dataset for testing\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eCreate new Linear Regression object \u003ccode\u003elrem1\u003c/code\u003e for multiple linear regression\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eUse method \u003ccode\u003efit()\u003c/code\u003e to train your model with the all features, except for 'Total'\u003c/b\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eFind the $R^{2}$ on the test data and train data using 30% of the dataset for testing\u003c/b\u003e\u003c/li\u003e\n","\u003cbr\u003e\n","\u003cb style=\"font-size:1.2em\"\u003eHint: you have test and train data from Question #1\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"7bae38a0-49ad-4df5-8938-1bca15a4227b","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"7d6224bb-8007-4af9-add5-66aaf413b5ef","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","lre1 = LinearRegression()\n","lre1.fit(x_train1[['Quantity']],y_train1)\n","lrem1 = LinearRegression()\n","lrem1.fit(x_train1,y_train1)\n","print(\"R^2 in SLR for test data: \",lre1.score(x_test1[['Quantity']],y_test1))\n","print(\"R^2 in SLR for train data: \",lre1.score(x_train1[['Quantity']],y_train1))\n","print()\n","print(\"R^2 in MLR for test data: \",lrem1.score(x_test1,y_test1))\n","print(\"R^2 in MLR for train data: \",lrem1.score(x_train1,y_train1))\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"5db507e3-df3c-4c3c-9f3e-790d6bca2e91","metadata":{},"outputs":[],"source":["Sometimes you do not have sufficient testing data; as a result, you may want to perform cross-validation. Let's go over several methods that you can use for cross-validation.\n"]},{"cell_type":"markdown","id":"45850cf2-5bcc-4815-8821-86a74ea55de4","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eCross-Validation Score\u003c/b\u003e\n"]},{"cell_type":"markdown","id":"5a52f332-a174-469f-8bce-df0024bb9439","metadata":{},"outputs":[],"source":["Let's use \u003cb\u003emodel_selection\u003c/b\u003e from the module \u003cb\u003ecross_val_score\u003c/b\u003e.\n"]},{"cell_type":"markdown","id":"cf09600c-a5a7-43f4-abdc-39877c9f2f50","metadata":{},"outputs":[],"source":["We input the object, the feature (\"Quantity\"), and the target data (y_data). The parameter 'cv' determines the number of folds. In this case, it is 3.\n"]},{"cell_type":"code","id":"8a3a56e5-fec9-4ac9-b5ab-028799954ea8","metadata":{},"outputs":[],"source":["Rcross = cross_val_score(lre, x_data[['Quantity']], y_data, cv = 3)"]},{"cell_type":"markdown","id":"afb14111-8fa7-4523-b5fe-29b1338cf64c","metadata":{},"outputs":[],"source":["The default scoring is $R^{2}$. Each element in the array has the average $R^{2}$ value for the fold:\n"]},{"cell_type":"code","id":"2162759d-27d8-4534-945f-5b2d5fd47e79","metadata":{},"outputs":[],"source":["Rcross"]},{"cell_type":"markdown","id":"9b4c8c7c-4eb4-4c5d-91e3-aadc89579787","metadata":{},"outputs":[],"source":["We can calculate the average and standard deviation of our estimate:\n"]},{"cell_type":"code","id":"bb42c5db-43ad-416f-b884-cafac2f2fef4","metadata":{},"outputs":[],"source":["print(\"The mean of the folds are {:.3f} and the standard deviation is {:.3f}\".format(Rcross.mean(), Rcross.std()))"]},{"cell_type":"markdown","id":"4b5415f5-4073-458a-b1ec-663943344d85","metadata":{},"outputs":[],"source":["We can use negative squared error as a score by setting the parameter  'scoring' metric to 'neg_mean_squared_error'.\n"]},{"cell_type":"code","id":"7287e051-7bdb-44db-920d-7f2ecfa808f7","metadata":{},"outputs":[],"source":["-1 * cross_val_score(lre,x_data[['Quantity']], y_data,cv = 3,scoring = 'neg_mean_squared_error')"]},{"cell_type":"markdown","id":"2cc1c326-ff8e-4288-bbfb-95fd413c07db","metadata":{},"outputs":[],"source":["Let's calculate the cross-validation score in case multiple linear regression\n"]},{"cell_type":"code","id":"9e82e6b1-410d-4e44-bc49-6bbbe7ef324e","metadata":{},"outputs":[],"source":["Rcrossm = cross_val_score(lrem, x_data, y_data, cv = 3)\nprint(\"The mean of the folds are {:.3f} and the standard deviation is {:.3f}\".format(Rcrossm.mean(), Rcrossm.std()))\nprint('The negative squared error\\n',\\\n     -1 * cross_val_score(lrem,x_data, y_data,cv = 3,scoring = 'neg_mean_squared_error'))"]},{"cell_type":"markdown","id":"d4e3961c-e4ed-4dc2-b818-969f0d2597bf","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003e Question  #3: \u003c/b\u003e\u003cbr\u003e\n","\u003cb style=\"font-size:1.2em\"\u003e \n","Calculate the average $R^{2}$ using four folds and standard deviation using Linear model \u003ccode\u003elre1\u003c/code\u003e and model \u003ccode\u003elrem1\u003c/code\u003e Set the parameter \u003ccode\u003ecv = 4\u003c/code\u003e\n","\u003c/b\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"b716bb55-00d9-4d3e-b838-f4a304725a96","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"d71cec08-e17e-49dc-bb84-27163b28b7b4","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","Rc = cross_val_score(lre1,x_data[['Quantity']], y_data,cv = 4)\n","Rc1 = cross_val_score(lrem1, x_data, y_data, cv = 4)\n","print(\"The mean of the folds are {:.3f} and the standard deviation is {:.3f}\".format(Rc.mean(), Rc.std()))\n","print(\"The mean of the folds are {:.3f} and the standard deviation is {:.3f}\".format(Rc1.mean(), Rc1.std()))\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"8665562b-abf3-411d-a83c-3421b93f2023","metadata":{},"outputs":[],"source":["You can also use the function 'cross_val_predict' to predict the output. The function splits up the data into the specified number of folds, with one fold for testing and the other folds are used for training.\n"]},{"cell_type":"markdown","id":"317df129-b21f-41bc-80df-e1aba2ea14cc","metadata":{},"outputs":[],"source":["We input the object, the feature \u003cb\u003e\"Quantity\"\u003c/b\u003e, and the target data \u003cb\u003ey_data\u003c/b\u003e. The parameter 'cv' determines the number of folds. In this case, it is 3. We can produce an output:\n"]},{"cell_type":"code","id":"50552075-281e-4cb8-9a99-5fc09417624e","metadata":{},"outputs":[],"source":["yhat = cross_val_predict(lre,x_data[['Quantity']], y_data,cv = 3)\nprint('PREDICTED VALUES\\n',yhat[0:5])\nprint('REAL VALUES\\n',y_data[0:5])"]},{"cell_type":"markdown","id":"ff27461e-747c-41d6-858f-70dcf23673b7","metadata":{},"outputs":[],"source":["And plot the predicted and real values\n"]},{"cell_type":"code","id":"58574aae-6a8e-4548-9c36-81089404c08a","metadata":{},"outputs":[],"source":["plt.figure()\nplt.title('Predicted values vs real values')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_data.index,y_data,label = 'Actual values')\nplt.plot(y_data.index,yhat,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"3370666e-e136-4cd3-9c02-ca3f9e80ef8b","metadata":{},"outputs":[],"source":["And for several predictors\n"]},{"cell_type":"code","id":"3ba34ac1-4b25-421a-89b7-8d7242f94541","metadata":{},"outputs":[],"source":["yhatm = cross_val_predict(lrem,x_data, y_data,cv = 3)\nprint('PREDICTED VALUES\\n',yhatm[0:5])\nprint('REAL VALUES\\n',y_data[0:5])"]},{"cell_type":"code","id":"320b4768-c39b-4e74-8dcc-dbaaf801f7c4","metadata":{},"outputs":[],"source":["plt.figure()\nplt.title('Predicted values vs real values')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_data.index,y_data,label = 'Actual values')\nplt.plot(y_data.index,yhatm,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"cdcf7f1f-261b-4522-b09e-2b016a5fb4bd","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.5em; font-weight: bold\"\u003e\u003ca name=\"id2\" style=\"text-decoration: none;\"\u003e\u003cfont color=\"black\"\u003e2. Underfitting and Model Selection\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n","\u003cp\u003eSometimes, our model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and test data. One reason for this is underfitting.\u003c/p\u003e\n","\u003cp\u003eGo over some examples. Let's see underfitting in Multiple Linear Regression and Polynomial Regression.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"60faf749-2596-42f3-8519-4bcb5576c32d","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eUnderfitting\u003c/b\u003e\n"]},{"cell_type":"markdown","id":"9ad60e6c-2447-43f6-8207-1ec17953c0e8","metadata":{},"outputs":[],"source":["We have model Multiple Linear Regression which we created before.\n","Prediction using training data:\n"]},{"cell_type":"code","id":"ecc5c1c6-d2b5-4d0c-96c6-57e34dd5d073","metadata":{},"outputs":[],"source":["yhat_train = lrem.predict(x_train)\nprint('PREDICTED TRAIN VALUES\\n',yhat_train[0:5])\nprint('REAL TRAIN VALUES\\n',y_train[0:5])"]},{"cell_type":"markdown","id":"1c5fbaf0-48fa-4195-8915-7b8d113c4a2c","metadata":{},"outputs":[],"source":["Prediction using test data:\n"]},{"cell_type":"code","id":"d29f93f5-7a31-4b6a-91f5-e97221f626f5","metadata":{},"outputs":[],"source":["yhat_test = lrem.predict(x_test)\nprint('PREDICTED TEST DATA\\n',yhat_test[0:5])\nprint('REAL TEST DATA\\n',y_test[0:5])"]},{"cell_type":"markdown","id":"eb8b2833-4160-4fda-9392-ed255756d87d","metadata":{},"outputs":[],"source":["Let's perform some model evaluation using our training and testing data separately.\n"]},{"cell_type":"markdown","id":"8381e56d-176a-4b3d-b1ce-59aa3faa5c64","metadata":{},"outputs":[],"source":["First, examine the distribution of the predicted values of the training data.\n"]},{"cell_type":"code","id":"d97523e3-d8cc-4a1e-a236-69ff9e7371e1","metadata":{},"outputs":[],"source":["Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\nDistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"]},{"cell_type":"markdown","id":"16c7a96b-1bda-45d5-ba21-2dabcad1833f","metadata":{},"outputs":[],"source":["**Figure 1**: Plot of predicted values using the training data compared to the actual values of the training data.\n"]},{"cell_type":"code","id":"305b0072-d7b4-45d3-9422-acdab7711381","metadata":{},"outputs":[],"source":["plt.figure()\nplt.title('Predicted values vs real values in Train data')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_train.index,y_train,label = 'Actual values')\nplt.plot(y_train.index,yhat_train,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"code","id":"d7c18f06-5b96-4b29-9ba1-c8c9aeb0e1b4","metadata":{},"outputs":[],"source":["Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\nDistributionPlot(y_test,yhat_test,\"Actual Values (Test)\",\"Predicted Values (Test)\",Title)"]},{"cell_type":"markdown","id":"5ab190ca-faa6-4116-a7c0-24012b8614e5","metadata":{},"outputs":[],"source":["**Figure 2**: Plot of predicted value using the test data compared to the actual values of the test data.\n"]},{"cell_type":"code","id":"3ab20a2f-b617-4eb4-860b-9b6c1557f6b7","metadata":{},"outputs":[],"source":["plt.figure()\nplt.title('Predicted values vs real values in Test data')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_test.index,y_test,label = 'Actual values')\nplt.plot(y_test.index,yhat_test,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"5ecfbd1f-54dd-4af2-9db5-598d1ea70a90","metadata":{},"outputs":[],"source":["Comparing **Figure 1** and **Figure 2**, you see that train data and test data is almost similar, but they different from real data\n"]},{"cell_type":"code","id":"168efae7-3449-438f-bdd3-e2dbc90c7886","metadata":{},"outputs":[],"source":["print('R^2 for train data: ',lrem.score(x_train,y_train))\nprint('R^2 for test data: ',lrem.score(x_test, y_test))"]},{"cell_type":"markdown","id":"62f4569b-60bd-4b1c-b983-0e03112114ca","metadata":{},"outputs":[],"source":["Let's use 60 percent of the data for training and the rest for testing:\n"]},{"cell_type":"code","id":"02b595bf-f518-4a9c-9e4d-165ea3e9b80a","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.4, shuffle = False)"]},{"cell_type":"markdown","id":"05be0c6d-660b-4d51-8546-de20cac75e96","metadata":{},"outputs":[],"source":["We will perform a degree 5 polynomial transformation on the feature \u003cb\u003e'Quantity'\u003c/b\u003e.\n"]},{"cell_type":"code","id":"eb50cf9e-4d29-4991-bbbf-59335d05c9a4","metadata":{},"outputs":[],"source":["pr = PolynomialFeatures(degree = 5)\nx_train_pr = pr.fit_transform(x_train[['Quantity']])\nx_test_pr = pr.fit_transform(x_test[['Quantity']])\npr"]},{"cell_type":"markdown","id":"2bbb21c4-0f50-4653-b73b-6b024643f081","metadata":{},"outputs":[],"source":["Now, let's create a Linear Regression model \"poly\" and train it.\n"]},{"cell_type":"code","id":"1d009a6b-be84-406c-8cd2-603f42fb3287","metadata":{},"outputs":[],"source":["poly = LinearRegression()\npoly.fit(x_train_pr, y_train)"]},{"cell_type":"markdown","id":"a30b6207-a1bc-4661-9730-fdc6b9060fe9","metadata":{},"outputs":[],"source":["We can see the output of our model using the method \"predict.\" We assign the values to \"yhat\".\n"]},{"cell_type":"code","id":"7b8cdf6e-f364-4059-a067-7604d931b07a","metadata":{},"outputs":[],"source":["yhat = poly.predict(x_test_pr)"]},{"cell_type":"markdown","id":"0476aa43-a9a4-455a-94de-fbc793cc61a3","metadata":{},"outputs":[],"source":["Let's take the first five predicted values and compare it to the actual targets.\n"]},{"cell_type":"code","id":"2a6bf4f3-eaa2-42ec-babc-72468a4ab6b5","metadata":{},"outputs":[],"source":["print(\"PREDICTED VALUES:\", yhat[0:5])\nprint(\"REAL VALUES:\", y_test[0:5].values)\n"]},{"cell_type":"markdown","id":"50e284ed-9dd3-4840-907a-2390b997daa7","metadata":{},"outputs":[],"source":["We will use the function \"PollyPlot\" that we defined at the beginning of the lab to display the training data, testing data, and the predicted function.\n"]},{"cell_type":"code","id":"4e266c5b-680e-47ee-8e97-7a9d6507444f","metadata":{},"outputs":[],"source":["PollyPlot(x_train[['Quantity']], x_test[['Quantity']], y_train, y_test, poly, pr)"]},{"cell_type":"markdown","id":"f264871a-b685-4e79-a582-25c48e30d360","metadata":{},"outputs":[],"source":["**Figure 3**: A polynomial regression model where red dots represent training data, green dots represent test data, and the blue line represents the model prediction.\n"]},{"cell_type":"code","id":"4cf4d361-462c-4f12-bc00-a4c0fd077d23","metadata":{},"outputs":[],"source":["plt.figure()\nplt.title('Predicted values vs real values in Test data')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_test.index,y_test,label = 'Actual values')\nplt.plot(y_test.index,yhat,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"c3b8aabe-39a5-4a38-930e-dd9eee45e8df","metadata":{},"outputs":[],"source":["We see that the estimated function appears to track the data but around 200 horsepower, the function begins to diverge from the data points.\n"]},{"cell_type":"markdown","id":"e41bbae9-4597-4e91-bd42-65eb13433c09","metadata":{},"outputs":[],"source":["$R^{2}$ of the training data:\n"]},{"cell_type":"code","id":"ddc473a3-fc09-45ef-b897-d711d31dfd60","metadata":{},"outputs":[],"source":["poly.score(x_train_pr, y_train)"]},{"cell_type":"markdown","id":"9b4a9507-2352-42d2-8d79-ea56ceae3ba5","metadata":{},"outputs":[],"source":["$R^{2}$ of the test data:\n"]},{"cell_type":"code","id":"0abb3300-0e1f-443e-9496-743f28c01c12","metadata":{},"outputs":[],"source":["poly.score(x_test_pr, y_test)"]},{"cell_type":"markdown","id":"4f3430cc-d5eb-4d79-ab58-65b72dae162f","metadata":{},"outputs":[],"source":["We see the $R^{2}$ for the training data is 0.77 while the $R^{2}$ on the test data was 0.73. This is example of underfitting when the score for train data and test are almost equal but they are not high.\n"]},{"cell_type":"markdown","id":"630946ba-7d2a-4e26-b7c7-734021f0a003","metadata":{},"outputs":[],"source":["Let's see how the $R^{2}$ changes on the test data for different order polynomials and then plot the results:\n"]},{"cell_type":"code","id":"fec4699d-add5-43b2-8b8e-bedf7b8b91d4","metadata":{},"outputs":[],"source":["Rsqu_test = []\n\norder = [1, 2, 3, 4, 5]\nfor n in order:\n    pr = PolynomialFeatures(degree = n)\n    \n    x_train_pr = pr.fit_transform(x_train[['Quantity']])\n    \n    x_test_pr = pr.fit_transform(x_test[['Quantity']])    \n    \n    lrem.fit(x_train_pr, y_train)\n    \n    Rsqu_test.append(lrem.score(x_test_pr, y_test))\n\nplt.plot(order, Rsqu_test)\nplt.xlabel('order')\nplt.ylabel('R^2')\nplt.title('R^2 Using Test Data')   "]},{"cell_type":"markdown","id":"18c84ded-643e-4459-a105-3b61592165e5","metadata":{},"outputs":[],"source":["The following function will be used in the next section. Please run the cell below.\n"]},{"cell_type":"code","id":"08ce53f6-d998-46df-a7d7-e802c339719b","metadata":{},"outputs":[],"source":["def f(order, test_data):\n    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = test_data, random_state = 0)\n    pr = PolynomialFeatures(degree = order)\n    x_train_pr = pr.fit_transform(x_train[['Quantity']])\n    x_test_pr = pr.fit_transform(x_test[['Quantity']])\n    poly = LinearRegression()\n    poly.fit(x_train_pr,y_train)\n    PollyPlot(x_train[['Quantity']], x_test[['Quantity']], y_train,y_test, poly, pr)"]},{"cell_type":"markdown","id":"170b725f-b637-4295-a868-79ca9565bdd8","metadata":{},"outputs":[],"source":["The following interface allows you to experiment with different polynomial orders and different amounts of data.\n"]},{"cell_type":"code","id":"edc022bd-96c1-4f02-a355-4e2d59b6a503","metadata":{},"outputs":[],"source":["interact(f, order = (0, 6, 1), test_data = (0.05, 0.95, 0.05))"]},{"cell_type":"markdown","id":"64742801-92d9-4dc4-9246-52ccf5e90e84","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: bold;\"\u003e Question  #4:\u003c/b\u003e\u003cbr\u003e\n","\u003cb style=\"font-size:1.2em\"\u003eWe can perform polynomial transformations with more than one feature.\u003c/b\u003e \n","\u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eCreate a \"PolynomialFeatures\" object \"pr1\" of degree two.\u003c/b\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eTransform the training and testing samples for the all features, except for 'Total'. Use the method \u003ccode\u003efit_transform()\u003c/code\u003e. Save training data in variable \u003ccode\u003ex_train_pr1\u003c/code\u003e, test data in variable \u003ccode\u003ex_test_pr1\u003c/code\u003e\u003c/b\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eFind dimensions for new feature for training data\u003c/b\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eCreate a linear regression model \"poly1\". Train the object using the method \"fit\" using the polynomial features.\u003c/b\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cb style=\"font-size:1.2em\"\u003eUse the method \"predict\" to predict an output on the polynomial features, then use the function \"DistributionPlot\" to display the distribution of the predicted test output vs. the actual test data.\u003c/b\u003e\u003c/li\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"fd18821a-5c91-4240-b46f-3a85c6c92ed1","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"d7ff48e8-ca98-4fd5-9acd-bd4b3bffcef8","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","pr1 = PolynomialFeatures(degree = 2)\n","x_train_pr1 = pr1.fit_transform(x_train)\n","x_test_pr1 = pr1.fit_transform(x_test)\n","print('Dimension of training data: ',x_train_pr1.shape)\n","poly1 = LinearRegression().fit(x_train_pr1,y_train)\n","yhat_test1 = poly1.predict(x_test_pr1)\n","Title = 'Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\n","DistributionPlot(y_test, yhat_test1, \"Actual Values (Test)\", \"Predicted Values (Test)\", Title)\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"47037c1f-4f3d-476d-afd5-cc9f79a0b2bc","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.5em; font-weight: bold\"\u003e\u003ca name=\"id3\" style=\"text-decoration: none;\"\u003e\u003cfont color=\"black\"\u003e3. Ridge Regression\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e \n"]},{"cell_type":"markdown","id":"aa7ef85a-6f36-4c48-848c-68034e997c7e","metadata":{},"outputs":[],"source":["In this section, we will review Ridge Regression and see how the parameter alpha changes the model. Just a note, here our test data will be used as validation data.\n"]},{"cell_type":"markdown","id":"58fef964-b17e-4abd-9fbb-285e3dbaaa17","metadata":{},"outputs":[],"source":["Let's perform a degree two polynomial transformation on our data.\u003cbr\u003e\n","\u003cb style=\"font-size: 1.2em; font-weight: bold;\"\u003eAttention! If you don't do previous task the next code will not run\u003c/b\u003e\n"]},{"cell_type":"markdown","id":"16e044a3-b96a-4880-9abe-36c082b5344c","metadata":{},"outputs":[],"source":["Let's create a Ridge regression object, setting the regularization parameter (alpha) to 0.1\n"]},{"cell_type":"code","id":"07bea51e-8ad2-4831-9c65-5acdb8c32a7d","metadata":{},"outputs":[],"source":["RidgeModel = Ridge(alpha = 0.1)"]},{"cell_type":"markdown","id":"a896ccfd-385d-4299-b548-9092e4461fcc","metadata":{},"outputs":[],"source":["Like regular regression, you can fit the model using the method \u003cb\u003efit\u003c/b\u003e.\n"]},{"cell_type":"code","id":"8450c49f-b578-4def-a96f-82d72ed96f6e","metadata":{},"outputs":[],"source":["RidgeModel.fit(x_train_pr1, y_train)"]},{"cell_type":"markdown","id":"d7ba12aa-dd6f-443b-93a5-7456aa1c10e9","metadata":{},"outputs":[],"source":["Similarly, you can obtain a prediction:\n"]},{"cell_type":"code","id":"b3f9754c-22ec-4aea-9fe8-300f38f70483","metadata":{},"outputs":[],"source":["yhat = RidgeModel.predict(x_test_pr1)"]},{"cell_type":"markdown","id":"59afc9da-7ad7-4e61-9d38-cca07fb942c5","metadata":{},"outputs":[],"source":["Let's compare the first five predicted samples to our test set:\n"]},{"cell_type":"code","id":"807e1889-44b7-40dc-b8f4-2ede58fa54d1","metadata":{},"outputs":[],"source":["print('predicted:', yhat[0:4])\nprint('test set :', y_test[0:4].values)\nplt.figure()\nplt.title('Predicted values vs real values in Test data')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_test.index,y_test,label = 'Actual values')\nplt.plot(y_test.index,yhat,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"98f06300-6edb-47fc-89da-7c39577fb84f","metadata":{},"outputs":[],"source":["We select the value of alpha that minimizes the test error. To do so, we can use a for loop. We have also created a progress bar to see how many iterations we have completed so far.\n"]},{"cell_type":"code","id":"6f6468f3-4bb0-415e-9fdd-9b52ef68c395","metadata":{},"outputs":[],"source":["Rsqu_test = []\nRsqu_train = []\ndummy1 = []\nAlpha = 0.1 * np.array(range(0,1000))\npbar = tqdm(Alpha)\n\nfor alpha in pbar:\n    RidgeModel = Ridge(alpha = alpha) \n    RidgeModel.fit(x_train_pr1, y_train)\n    test_score, train_score = RidgeModel.score(x_test_pr1, y_test), RidgeModel.score(x_train_pr1, y_train)\n    \n    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n\n    Rsqu_test.append(test_score)\n    Rsqu_train.append(train_score)"]},{"cell_type":"markdown","id":"b79175f3-8538-49f6-977b-f0c414963547","metadata":{},"outputs":[],"source":["We can plot out the value of $R^{2}$ for different alphas:\n"]},{"cell_type":"code","id":"66c5c9c9-4af1-41ee-801f-61773a547165","metadata":{},"outputs":[],"source":["width = 12\nheight = 10\nplt.figure(figsize = (width, height))\n\nplt.plot(Alpha,Rsqu_test, label = 'validation data  ')\nplt.plot(Alpha,Rsqu_train, 'r', label = 'training Data ')\nplt.xlabel('alpha')\nplt.ylabel('R^2')\nplt.legend()"]},{"cell_type":"markdown","id":"52e2869e-7219-4749-9a4e-d70744099aac","metadata":{},"outputs":[],"source":["**Figure 4**: The blue line represents the $R^{2}$ of the validation data, and the red line represents the $R^{2}$ of the training data. The x-axis represents the different values of Alpha.\n"]},{"cell_type":"markdown","id":"570b200e-db30-4c78-b6d3-463cdfbe945a","metadata":{},"outputs":[],"source":["Here the model is built and tested on the same data, so the training and test data are the same.\n","\n","The red line in Figure 4 represents the $R^{2}$ of the training data. As alpha increases the $R^{2}$ decreases. \n","\n","The blue line represents the $R^{2}$ on the validation data. As the value for alpha increases, the $R^{2}$ decreases.\n"]},{"cell_type":"markdown","id":"fb4e2975-2f92-44cf-bb0f-583ef70681e1","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 1.5em; font-weight: bold;\"\u003e Question  #5:\u003c/b\u003e\u003cbr\u003e\n","\n","Perform Ridge regression. Calculate the $R^{2}$ using the polynomial features, use the training data to train the model and use the test data to test the model. The parameter alpha should be set to 10.\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"69e375ed-53b9-4ffa-b456-9abd86963fe7","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"63867fd7-f5ae-4e1c-9880-e463bc301dfd","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","RidgeModel = Ridge(alpha=10) \n","RidgeModel.fit(x_train_pr1, y_train)\n","RidgeModel.score(x_test_pr1, y_test)\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"396ec5df-ac08-4ec1-8d3e-edef48b986c9","metadata":{},"outputs":[],"source":["\u003cb style=\"font-size: 1.5em; font-weight: bold\"\u003e\u003ca name=\"id4\" style=\"text-decoration: none\"\u003e\u003cfont color=\"black\"\u003e4. Grid Search\u003c/font\u003e\u003c/a\u003e\u003c/b\u003e\n"]},{"cell_type":"markdown","id":"a8d0bbd6-1d75-4eb6-8127-00308aea6c9e","metadata":{},"outputs":[],"source":["The term alpha is a hyperparameter. Sklearn has the class \u003cb\u003eGridSearchCV\u003c/b\u003e to make the process of finding the best hyperparameter simpler.\n"]},{"cell_type":"markdown","id":"7c810224-098b-4f78-a23f-6606aab1160b","metadata":{},"outputs":[],"source":["We create a dictionary of parameter values:\n"]},{"cell_type":"code","id":"7c70e588-3e47-4d74-a7c9-9240b55dca46","metadata":{},"outputs":[],"source":["parameters1= [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]\nparameters1"]},{"cell_type":"markdown","id":"58d019d9-61a8-45e8-b025-1d53c80632a1","metadata":{},"outputs":[],"source":["Create a Ridge regression object:\n"]},{"cell_type":"code","id":"a901e773-264b-4a25-aa58-4465c66fe57a","metadata":{},"outputs":[],"source":["RR=Ridge()\nRR"]},{"cell_type":"markdown","id":"1d72dfef-0f2d-42f3-8cbc-664872d6e071","metadata":{},"outputs":[],"source":["Create a ridge grid search object:\n"]},{"cell_type":"code","id":"be0177c3-7e7a-41a4-9dbc-b7c7700a557b","metadata":{},"outputs":[],"source":["Grid1 = GridSearchCV(RR, parameters1, cv = 3)"]},{"cell_type":"markdown","id":"c904aa92-cae6-4c5d-8c1c-166e8ef496ec","metadata":{},"outputs":[],"source":["Fit the model:\n"]},{"cell_type":"code","id":"519e19b4-e0a0-4120-b05b-e39f7b4a1908","metadata":{},"outputs":[],"source":["Grid1.fit(x_data, y_data)"]},{"cell_type":"markdown","id":"a1d68282-65f6-480a-9951-fd349f439219","metadata":{},"outputs":[],"source":["The object finds the best parameter values on the validation data. We can obtain the estimator with the best parameters and assign it to the variable BestRR as follows:\n"]},{"cell_type":"code","id":"84964d44-f365-41ee-a866-6a50f396ff78","metadata":{},"outputs":[],"source":["BestRR=Grid1.best_estimator_\nBestRR"]},{"cell_type":"markdown","id":"52aa2b8b-85ae-4e80-b73e-0a668529c868","metadata":{},"outputs":[],"source":["We now test our model on the test data:\n"]},{"cell_type":"code","id":"332d06b5-fdda-4d38-8115-fdea56d07602","metadata":{},"outputs":[],"source":["BestRR.score(x_test, y_test)"]},{"cell_type":"markdown","id":"65478ce4-3920-4927-844b-a45540349e3b","metadata":{},"outputs":[],"source":["Let's plot the real test data and predicted test data with the best alpha parameter\n"]},{"cell_type":"code","id":"59a0e72c-ac8d-495f-b037-3ed095658973","metadata":{},"outputs":[],"source":["yhat = BestRR.predict(x_test)\nplt.figure()\nplt.title('Predicted values vs real values in Test data')\nplt.xlabel('Index')\nplt.ylabel('Total cost')\nplt.plot(y_test.index,y_test,label = 'Actual values')\nplt.plot(y_test.index,yhat,label = 'Predicted values')\nplt.legend()"]},{"cell_type":"markdown","id":"5e771934-b88a-402d-af33-339a83951aae","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","## Authors\n","\n","\u003ca href=\"https://author.skills.network/instructors/victor_dyrenko?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0TE4EN3049-2023-01-01\"\u003eVictor Dyrenko\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0TE4EN3049-2023-01-01\"\u003eYaroslav Vyklyuk\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/olga_kavun?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0TE4EN3049-2023-01-01\"\u003eOlga Kavun\u003c/a\u003e\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version |     Changed By   | Change Description                                         |\n","| ----------------- | ------- | ---------------- | ---------------------------------------------------------- |\n","| 2023-05-05        | 1       | Victor Dyrenko   | Finished lab                                               |\n","\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2023. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}