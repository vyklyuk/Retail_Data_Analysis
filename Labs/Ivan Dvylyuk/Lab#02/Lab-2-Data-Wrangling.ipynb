{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4964d92-e648-4b25-92e4-b7e3c3536f41",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n<h1 style=\"font-size: 36px; font-weight: bold; margin-top: 20px; text-decoration: none; margin-bottom: 25px;\">Forecasting the turnover of supermarkets</h1>\n<h2 style=\"font-size: 32px; font-weight: 500; margin-top: 0;\">Lab. 2. Data Wrangling</h2>\n\nEstimated time needed: **30** minutes\n\n## Context\n<details><summary>Click here to learn more about the purpose of the labs</summary>\n\nIn the dataset, you'll get data of different stores of a supermarket company. Our goals of analysis are:\n<ol>\n    <li>Calculate:</li>\n    <ul>\n    <li>Average sales volume per customer;</li>\n    <li>Average sales volume per 1 square meter of store area;</li>\n    </ul>\n    <li>Investigate how indicators such as the number of customers, the number of products, and the size of store area affect the turnover volume;</li>\n    <li>Calculate the forecast value of turnover for the next period;</li>\n</ol>\n    \n</details>\n\n## Incoming data\n<details><summary>Click here to learn more about the incoming data</summary>\n\n<p>The dataset contains information on sample parameters from 896 supermarkets: store identifier, retail store area, number of product categories for sale, average monthly customer traffic, turnover volume.</p>\n<ul>\n    <li>Store ID: (Index) ID of the particular store;</li>\n    <li>Store Area: Physical Area of the store in yard square;</li>\n    <li>Items Available: Number of different items available in the corresponding store;</li>\n    <li>Daily Customer Count: Number of customers who visited to stores on an average over month;</li>\n    <h3>Target value</h3>\n    <li>Store Sales: Sales in (US $) that stores made;</li>\n</ul>\n    \n</details>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c1e3ba-2d72-4482-b946-855b55f6b836",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"#data_acquisition\">Data Acquisition</a></li>\n    <li><a href=\"#identify_missing_values\">Identify missing values</a></li>\n        <li><a href=\"#add_new_column\">Adding new column</a></li>\n    <li><a href=\"#sort_data\">Sorting Data</a></li>\n    <li><a href=\"#data_normalization\">Data normalization</a></li>\n    <li><a href=\"#binning\">Binning</a></li>\n    <li><a href=\"#groping_data\">Groung Data</a></li>\n</ol>\n\n</div>\n\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305d26ea-dc61-42ba-a1ab-0d7c5386764c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"data_acquisition\" style=\"text-decoration: none;\">\n        <font color=\"black\">Data Acquisition</font>\n    </a>\n</b>\n<details><summary>Сlick here to learn more about the dataframe</summary>\n<br>   \n<p>In our case, the Store Dataset is an online source, and it is in a CSV (comma separated value) format. We use this dataset as an example to practice data reading. </p>\n\n<ul>\n    <li>Data source: <a href=\"https://www.kaggle.com/datasets/surajjha101/stores-area-and-sales-data/download?datasetVersionNumber=1\" target=\"_blank\">https://www.kaggle.com/datasets/surajjha101/stores-area-and-sales-data</a></li>\n    <li>Data type: csv</li>\n    <li>Licence: <a href=\"https://creativecommons.org/licenses/by-sa/3.0/\">CC BY-SA 3.0</a></li>\n</ul>\n \n<p>This DataSet released under CC0: Public Domain license that allow of copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission.</p>\n\n\n\n\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8da5044-3d92-4d41-94b1-5daac40b97b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "## What is the purpose of data wrangling?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfbc4c8-1ac1-4b3b-9df3-bfe9ea6d2f03",
      "metadata": {},
      "outputs": [],
      "source": [
        "Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a6ff9cd-6d62-442f-a5dc-8797753862d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Import data\n<p>\nYou can find the \"Supermarket store branches sales analysis Dataset\" from the following link: <a href=\"https://www.kaggle.com/datasets/surajjha101/stores-area-and-sales-data/code\">link</a>. \nWe will be using this dataset throughout this course.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f976e2bd-de61-4fc4-8197-5f14b2bb3672",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Import libraries \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1caf0f7-f4bc-457d-a9f2-a235b327ef10",
      "metadata": {},
      "outputs": [],
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f4976500-6baa-4f41-82fe-59200cba8e51",
      "metadata": {},
      "outputs": [],
      "source": [
        "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n#install specific version of libraries used in lab\n#! mamba install pandas==1.3.3 -y\n#! mamba install numpy=1.21.2 -y\n "
      ]
    },
    {
      "cell_type": "code",
      "id": "cfbfc16b-6324-48b4-b0eb-94da37452ea3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f457cb69-5bd8-4de6-8fbd-908e212b0546",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Reading the dataset from the URL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa67ef7-5b6f-41ad-bed7-0fa938829e5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "First, we assign the URL of the dataset to \"filename\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "161c598a-53e6-428d-9165-e67d1ad83055",
      "metadata": {},
      "outputs": [],
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8c1b1f95-369d-4bd8-a4fe-a6f94dd7bac3",
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0QTOEN/Stores.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7f3935-1185-45ec-90bc-82bef5a8e96c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Use the Pandas method <b>read_csv()</b> to load the data from the web address. Set the parameter \"index_col\" equal 0 so that pandas will set the first column as the index column.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6f47118b-9a8f-446e-b43c-e541cd617e27",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(filename, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61cef57d-9011-4f93-b009-cc5aea8411ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "Before starting to perform operations on the data, we need to ensure that our dataframe is ready for further analysis.\n\n<div>We need to check if the data contains any missing values or type mismatches, and if so, we need to address these issues.</div> \n\n<b>How to work with missing data?</b>\n\nSteps for working with missing data:\n\n<ol>\n    <li>Identify missing data</li>\n    <li>Deal with missing data</li>\n    <li>Correct data format</li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173300ae-ef7b-4ded-a494-9e4a4665ba3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"identify_missing_values\" style=\"text-decoration: none;\">\n        <font color=\"black\">Identify missing values</font>\n    </a>\n</b><br>\nThe missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n\n<ol>\n    <li><b>.isnull()</b></li>\n    <li><b>.notnull()</b></li>\n</ol>\nThe output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d85c4a4-f5af-4b4d-9abf-e47443aa3634",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\nmissing_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bab50bf-9ee9-42a6-beab-cd813f915863",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a40a8e8c-023e-47ef-b82b-a0e17f27fc8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Count missing values in each column\n<p>\nUsing a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method \".value_counts()\" counts the number of \"True\" values. \n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "776d1394-4dff-488a-b807-452fce7cdd24",
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa88c3c1-435d-472d-86a0-c07cabd90990",
      "metadata": {},
      "outputs": [],
      "source": [
        "Based on the summary above, each column has 896 rows of data and no column containing any missing data:\n\n<ol>\n    <li>\"Store Area\": 0 missing data</li>\n    <li>\"Items Available\": 0 missing data</li>\n    <li>\"Daily Customer Count\": 0 missing data</li>\n    <li>\"Store Sales\" : 0 missing data</li>\n</ol>\n\n<b>Great!</b> We have a dataset with no missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc8770a-5245-43f6-8577-7a99cd5d937a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Correct data format\n\n<p>The last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).</p>\n\nIn Pandas, we use:\n\n<p><b>.dtype()</b> to check the data type</p>\n<p><b>.astype()</b> to change the data type</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba249e8-d1e7-4bf0-8b13-242a4a17f0aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Let's list the data types for each column\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ac4e48bf-e6f3-4d7e-83e3-bec8b9548edb",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45dcee57-af03-49af-b040-7e5d708c4e50",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>As all the columns in our DataFrame consist of integers, the output confirms that all the data is of the correct data type, and there is no need to make any modifications.</p> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1262af48-46d6-414b-9168-4d1213164e7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"add_new_column\" style=\"text-decoration: none;\">\n        <font color=\"black\">Adding new column</font>\n    </a>\n</b><br>\n\n<p><b>Target:</b> Add a column that represents the average amount of sales per customer by dividing the \"Store Sales\" column by the \"Daily Customer Count\" column</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6454668f-f2c6-4777-9fed-e8c3bdf273c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "To add a column to a Pandas dataframe, you can use the bracket notation and assign a value or a list of values to the new column label. So"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ff1c10ac-c1ab-426e-a8ad-e1e798e60bd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['new_column'] = some_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d1480a-691a-465c-b53f-e2c7e537ed86",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the average sales volume per customer and add the values to a new column:"
      ]
    },
    {
      "cell_type": "code",
      "id": "9102b76a-3ad4-4f2b-8805-cb8e589324ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Revenue per Customer'] = df['Store Sales'] / df['Daily Customer Count']\ndf.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6696d716-9cfe-4d6e-8d3f-00d21031c76b",
      "metadata": {},
      "outputs": [],
      "source": [
        "To add a new column at a specific position, you can use the <code>insert()</code> method. This method takes three arguments: the position at which to insert the column, the name of the new column, and the data to populate the new column."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f77323b-6fde-4ef4-8bdb-fbf3517f952e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 32px; font-weight: bold;\"> Question #1: </b>\n\n<b>Add a new column 'Sales per Store Area' for the average sales volume per 1 square meter of the sales area ('Store Sales divided by 'Store Area') to the second-to-last position</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "015499c0-41de-43b9-b40e-defb11524aca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc2dbb9-788d-4360-833a-5cfefb7df92e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf.insert(len(df.columns)-1, 'Sales per Store Area', df['Store Sales'] / df['Store Area'])\ndf.head(10)\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0113ed37-c0ed-4c84-ab65-d2ea88cd1632",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"sort_data\" style=\"text-decoration: none;\">\n        <font color=\"black\">Sorting Data</font>\n    </a>\n</b><br>\n<b>What is data sorting?</b>\n<p>\n    Sorting refers to the process of arranging or reordering the rows and columns of a DataFrame based on certain criteria.\n</p>\n<b>Why we use sorting?</b>\n<p>\n    It allows us to quickly identify the highest or lowest values, the most frequent categories, and the relationships between different variables.\n</p>\n\n<b>Example:</b>\n<p>In our dataset, all \"Store Area\" values are ordered by index. But what if we want to find out which store has the largest/smallest area?</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2809f164-8f2d-45e3-b6a5-7cff88637d2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Sorting by a Single Column\n<p>To sort the dataframe by a single column, you can use the <code>sort_values()</code> method. Let's sort our dataframe by the \"Store Area\" column in descending order:</p>"
      ]
    },
    {
      "cell_type": "code",
      "id": "a383d6f9-cccb-4156-a011-4be9491ec953",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sort_values(by='Store Area', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac11b8b-fc43-462c-a4a5-c56a76877acb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Note that we set <code>ascending=False</code> to sort in descending order. If you want to sort in ascending order, you can simply omit the ascending parameter or set it to \"True\".<p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3547979-bfd9-4c67-b786-71dfa862c712",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Sorting by Multiple Columns\n<p>You can also sort a DataFrame by multiple columns. For example, let's sort our dataframe first by \"Items Available\" in ascending order, and then by \"Daily Customer Count\" in descending order</p>"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd355bc0-d7a2-407b-90eb-a4bb21ca3d06",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sort_values(by=['Items Available', 'Daily Customer Count'], ascending=[True, False])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef129ff9-d452-450a-9a7c-584e518532da",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 32px; font-weight: bold;\"> Question #2: </b>\n\n<b>Sort the dataframe by the Store Area column in descending order and the Store Sale column in ascending order.</b><br>\n    \n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "bd03cf1b-5390-4397-9bde-fb824e53a46e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c524e763-b65f-42ea-93bf-b516717d62d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf.sort_values(by=['Store Area', 'Store Sales'], ascending=[False, True])\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0151784e-b450-4cc2-898c-a87cef9a2c5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"data_normalization\" style=\"text-decoration: none;\">\n        <font color=\"black\">Data Normalization</font>\n    </a>\n</b><br>\n<b>Why normalization?</b>\n\n<p>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the variable so the variable values range from 0 to 1.\n</p>\n\n<b>Example</b>\n\n<p>To demonstrate normalization, let's say we want to scale the column \"Store Sales\".</p>\n<p><b>Target:</b> would like to normalize this variable so its value ranges from 0 to 1</p>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8b7735-b905-4a0f-8cde-540242a7fbd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>We can use two main approaches for normalization:</b>\n<ol>\n    <li>replacing original value by (original value)/(maximum value)</li>\n</ol>"
      ]
    },
    {
      "cell_type": "code",
      "id": "f1955f11-a311-4208-8630-fdd9511081e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace (original value) by (original value)/(maximum value)\nnorm = df['Store Sales']/df['Store Sales'].max()\nprint(norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38be4ea-ed7e-4fb6-a0ae-dd257702e65e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<ol start=2>\n    <li>using the <code>preprocessing</code> module from the scikit-learn library</li>\n</ol>"
      ]
    },
    {
      "cell_type": "code",
      "id": "ae4dc506-7736-4c8a-ba55-0d1d6dfb1c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\nnorm = scaler.fit_transform(df[['Store Sales']])\nprint(norm[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4925f47-2b3d-4412-974a-53cbd72750c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nHere we use the <code>MinMaxScaler</code> class, which performs scaling using minimum and maximum values.\n\nThe <code>fit_transform()</code> method performs two actions: first, it computes the minimum and maximum values for the 'Store Sales' column in the dataframe, and then it scales the values of this column to the range of 0 to 1.\n</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b210e8cf-a0b6-469b-94bc-34e639587e67",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 32px; font-weight: bold;\"> Question #3: </b>\n\n<b>According to the first example above, normalize the column \"Store Area\".</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cad866d8-eb51-4918-8a9e-d6f6b169eaef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97cd7355-04ee-4f12-9773-e3e451d2bf0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nnorm = df['Store Area']/df['Store Area'].max()\nnorm\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b01acf5-3bb3-47a2-81a4-36d3f2c266db",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"binning\" style=\"text-decoration: none;\">\n        <font color=\"black\">Binning</font>\n    </a>\n</b><br>\n<b>Why binning?</b>\n<p>\n    Binning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.\n</p>\n\n<b>Example: </b>\n\n<p>In our dataset, \"Store Area\" is a real valued variable ranging from 775 to 2229. What if we only care about the stores with large, medium, or small area?(3 types)? Can we rearrange them into three ‘bins' to simplify analysis? </p>\n\n<p>We will use the pandas method 'cut' to segment the 'Store Area' column into 3 bins.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a971e231-3ef2-4259-ac7e-734f9c88ff8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Example of Binning Data In Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ba078a-c200-4f61-a87f-b18b62441566",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's plot the histogram of 'Sales per Store Area' to see the sales volume per unit area of the stores.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "48fd116c-f0be-4ae9-86c4-2691be57acb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.hist(df[\"Sales per Store Area\"])\n\n# Set x/y labels and plot title\nplt.xlabel(\"Sales per Store Area\")\nplt.ylabel(\"Amount\")\nplt.title(\"Sales per Store Area bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6691ac47-9614-4621-a8c6-f3c5ccd745a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>We would like 3 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated</code> function.</p>\n<p>Since we want to include the minimum value, we want to set start_value = min(df[\"Sales per Store Area\"]).</p>\n<p>Since we want to include the maximum value, we want to set end_value = max(df[\"Sales per Store Area\"]).</p>\n<p>Since we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated = 4.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "017cabed-67ef-471f-9795-c4ba3a7eb16d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\nsales_area_bins = np.linspace(math.floor(min(df[\"Sales per Store Area\"])), max(df[\"Sales per Store Area\"]), 4)\nsales_area_bins"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "154fb1ff-f471-4dab-8d40-3287fad33418",
      "metadata": {},
      "outputs": [],
      "source": [
        "We set group  names:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b3c87679-9d0b-46f3-8ad0-aba9d09ace09",
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_area_labels = ['Low', 'Middle', 'High']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c9fbb8-148a-4e81-ac34-1ee99c32519e",
      "metadata": {},
      "outputs": [],
      "source": [
        "We apply the function \"cut\" to determine what each value of `df[\"Sales per Store Area\"]` belongs to.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e41306a5-c781-49ad-bb11-56a0e575731d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Sales-per-Store-Area-binned\"] = pd.cut(df['Sales per Store Area'], bins=sales_area_bins, labels=sales_area_labels)\ndf[['Sales per Store Area',\"Sales-per-Store-Area-binned\"]].head(853)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7acc7ce-4cfa-49e4-b594-1997deac330d",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see the number of stores in each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "85e2b732-d8ad-4332-9369-047738753405",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Sales-per-Store-Area-binned\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefab1ad-3a28-457d-8370-d80b25054a9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's plot the distribution of each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6d2da218-74fb-41d8-9782-5776623cefaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(sales_area_labels, df[\"Sales-per-Store-Area-binned\"].value_counts())\n\n# set x/y labels and plot title\nplt.xlabel(\"Sales per Store Area\")\nplt.ylabel(\"Amount\")\nplt.title(\"Sales per Store Area bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d76c95-23e7-4a5e-9e86-61d6fd5e8c62",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nLook at the dataframe above carefully. You will find that the last column provides the bins for 'Sales per Store Area' based on 3 categories (\"Low\", \"Middle\" and \"High\"). \n</p>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ff3c5ca-b877-422a-9c9f-c63ff565900a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Bins Visualization\nNormally, a histogram is used to visualize the distribution of bins we created above. \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "49deff71-4902-41fb-a2f1-dc6985e0065f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# draw historgram of attribute \"Store Area\" with bins = 3\nplt.hist(df[\"Sales per Store Area\"], bins = 3)\n\n# set x/y labels and plot title\nplt.xlabel(\"Sales per Store Area\")\nplt.ylabel(\"Amount\")\nplt.title(\"Sales per Store Area bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d75f51f-0170-465f-9a22-39b7c0142299",
      "metadata": {},
      "outputs": [],
      "source": [
        "The plot above shows the binning result for the attribute 'Sales per Store Area'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "133baca5-cc03-429e-ba09-3b1e82f4a8a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 32px; font-weight: bold;\"> Question #4: </b>\n\n<b>Separate the column \"Store Area\" into 3 bins of '1-999', '1000-1499', '1500-inf'. Call the new column 'Store-Area-binned'</b><br>\n<p>Hint! This problem can be divided into three tasks:</p>\n<ol>\n    <li>Generating a bin array;</li>\n    <li>Creating an array to store labels (the same as bins);</li>\n    <li>Dividing the data into bins using the <code>.cut()</code> function;</li>\n</ol>\n\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5c5aaf5e-8c63-4e37-a3eb-44de1995561c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \nstore_area_bins = [1, 999, 1499, max(df[\"Store Area\"])]\nstore_area_names = ['1-999', '1000-1499', '1500-inf']\ndf['Store-Area-binned'] = pd.cut(df['Store Area'], bins=store_area_bins, labels=store_area_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8410f1b-6da5-40f9-ac97-682bcd4366f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\nstore_area_bins = [1, 999, 1499, max(df[\"Store Area\"])]\nstore_area_names = ['1-999', '1000-1499', '1500-inf']\ndf['Store-Area-binned'] = pd.cut(df['Store Area'], bins=store_area_bins, labels=store_area_names)\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413398f6-5948-48ce-b2a7-5e171efd8580",
      "metadata": {},
      "outputs": [],
      "source": [
        "It's important to complete this task, as the result will be needed for creating a crosstable later on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946676a6-c09c-4f39-9c49-fdbd2655bff4",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<b style=\"font-size: 32px; font-weight: 500; text-decoration: none; padding-top: 20px;\">\n    <a name=\"groping_data\" style=\"text-decoration: none;\">\n        <font color=\"black\">Groung Data</font>\n    </a>\n</b><br>\n<b>What is data grouping?</b>\n<p>\nGrouping refers to the process of splitting the data into groups based on some criteria and applying a function to each group.    \n</p>\n<b>Why we use grouping?</b>\n<p>\nGrouping allows us to perform aggregate functions, such as counting, summing, or averaging, on subsets of data based on a particular attribute or combination of attributes.\n</p>\n<b>Example:</b>\n<p>\n In our dataset, we want to find out, for example, how many stores have an area between 1000 and 1499 square meters and count of daily customers ranging from 500 to 999.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b02d25-8669-4b01-80d1-fb4e6b03ba72",
      "metadata": {},
      "outputs": [],
      "source": [
        "Before moving on to grouping the data, we need to create another column that will categorize the number of visitors to the stores into 3 groups: 1-499, 500-999, 1000-inf. We have performed similar actions a little earlier."
      ]
    },
    {
      "cell_type": "code",
      "id": "6a5ad251-aee2-411d-a9ca-47e586ee5d27",
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_count_bins = [1, 499, 999, max(df[\"Daily Customer Count\"])]\ncustomers_count_names = ['1-499', '500-999', '1000-inf']\ndf['Customers-Count-binned'] = pd.cut(df['Daily Customer Count'], bins=customers_count_bins, labels=customers_count_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f93335e-de55-4917-9c70-fb2bd110af3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "To group data, we use the <code>groupby()</code> method. This method can be called on a dataframe object and passed one or several columns by which the data should be grouped."
      ]
    },
    {
      "cell_type": "code",
      "id": "3f5f0c0f-f61f-471d-9ef0-adb2c168ca63",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = df.groupby(['Store-Area-binned', 'Customers-Count-binned']).size().reset_index(name='Count')\nprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59670917-89f4-4417-867b-f519024be78c",
      "metadata": {},
      "outputs": [],
      "source": [
        "The above code groups by two columns: 'Store-Area-binned' and 'Customers Count-binned'. Then calculates the number of rows in each group using the <code>size()</code> method. The <code>reset_index()</code> method is used to reset the index of the resulting dataframe and name the new column with the count values as 'Count'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e27847-1ba8-42e0-a794-03fcf5f78c25",
      "metadata": {},
      "outputs": [],
      "source": [
        "After grouping, we can use <code>crosstab()</code> to obtain a summary table showing the count of observations for each combination of values within the groups."
      ]
    },
    {
      "cell_type": "code",
      "id": "d0255fca-bc80-4a09-a24d-2a75a2c6848b",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.crosstab(result['Store-Area-binned'], result['Customers-Count-binned'], \n                              values=result['Count'], aggfunc='sum', \n                              rownames=['Store Area'], colnames=['Daily Customer Count'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60fbb3fc-b032-4583-93dc-41048a648b53",
      "metadata": {},
      "outputs": [],
      "source": [
        "Here the first argument represents the row variable and the second is the column variable. <code>aggfunc='sum'</code> specifies the aggregation function to be used, which is sum in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1b67c06-fc4a-455a-b604-0f4068a98ebb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 32px; font-weight: bold;\"> Question #5: </b>\n\n<b>Create a cross-tabulation based on the columns 'Store-Area-binned' and \"Sales-per-Store-Area-binned\", which was calculated in the previous section.</b><br>\n    \n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cf188803-7ad5-4c02-9ce4-69ac545a4e48",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \nresult = df.groupby(['Store-Area-binned', \"Sales-per-Store-Area-binned\"]).size().reset_index(name='Count')\npd.crosstab(result['Store-Area-binned'], result[\"Sales-per-Store-Area-binned\"], \n                              values=result['Count'], aggfunc='sum', \n                              rownames=['Store Area'], colnames=['Sales per Store Area'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb160a3e-9774-407e-8f0e-1f59be255d62",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nresult = df.groupby(['Store-Area-binned', \"Sales-per-Store-Area-binned\"]).size().reset_index(name='Count')\npd.crosstab(result['Store-Area-binned'], result[\"Sales-per-Store-Area-binned\"], \n                              values=result['Count'], aggfunc='sum', \n                              rownames=['Store Area'], colnames=['Sales per Store Area'])\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "81e3b299-8772-40f6-8d3c-151541024034",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('Stores.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaaa5d58-32d1-4c2b-9b5c-6ce0f0592547",
      "metadata": {},
      "outputs": [],
      "source": [
        "Save the new csv:\n\n> Note : The  csv file cannot be viewed in the jupyterlite based SN labs environment.However you can Click <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%202/DA0101EN-2-Review-Data-Wrangling.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2022-01-01\">HERE</a> to download the lab notebook (.ipynb) to your local machine and view the csv file once the notebook is executed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8748e64a-b553-4f2c-88df-52cc261ab3b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Thank you for completing this lab!\n\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/ivan_dvylyuk\">Ivan Dvylyuk</a>\n\n### Other Contributors\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2\">Yaroslav Vyklyuk</a>\n\n<a href=\"https://author.skills.network/instructors/olga_kavun\">Olga Kavun</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                            |\n| ----------------- | ------- | ---------- | --------------------------------------------- |\n| 2023-04-03        | 2.2     | Ivan       | Created the lab                               |\n\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}